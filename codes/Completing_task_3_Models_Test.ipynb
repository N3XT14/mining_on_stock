{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"84AtUsH0bo3w","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683249951864,"user_tz":240,"elapsed":7426,"user":{"displayName":"Praneeth","userId":"13740106769956375743"}},"outputId":"085f645f-d474-4f9d-9eb2-1f4651867101"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["#Necessary Imports\n","# !pip install ta\n","import numpy as np\n","import pandas as pd\n","import os\n","import pickle\n","import torch\n","# import ta\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","#Data Source Location\n","os.chdir(\"/content/drive/My Drive/mining-on-stock\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ckORrrbKbssR"},"outputs":[],"source":["#Load Feature Engineered Stock dataset: 100 Features including labels\n","with open('data_with_features_clean_train.pkl', 'rb') as train_file: #To do: Change file name.\n","  train_data = pickle.load(train_file)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cBVXZ03BYD91","colab":{"base_uri":"https://localhost:8080/","height":369},"executionInfo":{"status":"ok","timestamp":1683249963468,"user_tz":240,"elapsed":166,"user":{"displayName":"Praneeth","userId":"13740106769956375743"}},"outputId":"7816ec4d-5c7f-4038-e292-47136dcd740f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Last 5 datapoints of the first stock among 2000 stocks\n"]},{"output_type":"execute_result","data":{"text/plain":["          Open      High       Low     Close    Volume  \\\n","2197  0.680849  0.683633  0.672997  0.674055  0.351048   \n","2198  0.674389  0.674890  0.671326  0.674055  0.143069   \n","2199  0.674110  0.676227  0.672440  0.676004  0.312048   \n","2200  0.675725  0.675837  0.668820  0.669321  0.279230   \n","2201  0.669293  0.671326  0.662973  0.664198  0.552933   \n","\n","      awesome_oscillator (AO)  bollinger_percent_b (percent_b)  cfo (cfo)  \\\n","2197                 0.010157                         0.744441   0.068595   \n","2198                 0.010020                         0.723160   0.068595   \n","2199                 0.010509                         0.755154   0.068595   \n","2200                 0.008306                         0.536443   0.068595   \n","2201                 0.005024                         0.362143   0.068595   \n","\n","      cmo (cmo)  detrended_price_oscillator (dpo)  ...  \\\n","2197  21.168686                          0.004813  ...   \n","2198  19.300231                          0.005677  ...   \n","2199  21.857938                          0.008792  ...   \n","2200  18.491048                          0.003247  ...   \n","2201  15.904361                         -0.000906  ...   \n","\n","      ichimoku_clouds (senkou_span_a)  ichimoku_clouds (chikou_span)  \\\n","2197                         0.683299                       0.689504   \n","2198                         0.682909                       0.689504   \n","2199                         0.682505                       0.689504   \n","2200                         0.682505                       0.689504   \n","2201                         0.679735                       0.689504   \n","\n","      keltner_channel (Keltner Center)  keltner_channel (Keltner Upper)  \\\n","2197                          0.677062                         0.692473   \n","2198                          0.677206                         0.692105   \n","2199                          0.677414                         0.691979   \n","2200                          0.677475                         0.692413   \n","2201                          0.677201                         0.691448   \n","\n","      keltner_channel (Keltner Lower)  linear_reg_forecast (LRF)  \\\n","2197                         0.661650                   0.689504   \n","2198                         0.662307                   0.689504   \n","2199                         0.662849                   0.689504   \n","2200                         0.662537                   0.689504   \n","2201                         0.662953                   0.689504   \n","\n","      mass_index (Mass_Index)  median_price (Median Price)  \\\n","2197                 1.080827                     0.678315   \n","2198                 0.966600                     0.673108   \n","2199                 0.896525                     0.674333   \n","2200                 0.925453                     0.672328   \n","2201                 0.977753                     0.667149   \n","\n","      money_flow_index (Money Flow Index)          Label  \n","2197                             7.843752       decrease  \n","2198                             7.179743  no big change  \n","2199                             7.179743       increase  \n","2200                             7.535366       decrease  \n","2201                             7.707911       decrease  \n","\n","[5 rows x 101 columns]"],"text/html":["\n","  <div id=\"df-c3649a63-f632-40b7-a026-da6a6de379ad\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Open</th>\n","      <th>High</th>\n","      <th>Low</th>\n","      <th>Close</th>\n","      <th>Volume</th>\n","      <th>awesome_oscillator (AO)</th>\n","      <th>bollinger_percent_b (percent_b)</th>\n","      <th>cfo (cfo)</th>\n","      <th>cmo (cmo)</th>\n","      <th>detrended_price_oscillator (dpo)</th>\n","      <th>...</th>\n","      <th>ichimoku_clouds (senkou_span_a)</th>\n","      <th>ichimoku_clouds (chikou_span)</th>\n","      <th>keltner_channel (Keltner Center)</th>\n","      <th>keltner_channel (Keltner Upper)</th>\n","      <th>keltner_channel (Keltner Lower)</th>\n","      <th>linear_reg_forecast (LRF)</th>\n","      <th>mass_index (Mass_Index)</th>\n","      <th>median_price (Median Price)</th>\n","      <th>money_flow_index (Money Flow Index)</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2197</th>\n","      <td>0.680849</td>\n","      <td>0.683633</td>\n","      <td>0.672997</td>\n","      <td>0.674055</td>\n","      <td>0.351048</td>\n","      <td>0.010157</td>\n","      <td>0.744441</td>\n","      <td>0.068595</td>\n","      <td>21.168686</td>\n","      <td>0.004813</td>\n","      <td>...</td>\n","      <td>0.683299</td>\n","      <td>0.689504</td>\n","      <td>0.677062</td>\n","      <td>0.692473</td>\n","      <td>0.661650</td>\n","      <td>0.689504</td>\n","      <td>1.080827</td>\n","      <td>0.678315</td>\n","      <td>7.843752</td>\n","      <td>decrease</td>\n","    </tr>\n","    <tr>\n","      <th>2198</th>\n","      <td>0.674389</td>\n","      <td>0.674890</td>\n","      <td>0.671326</td>\n","      <td>0.674055</td>\n","      <td>0.143069</td>\n","      <td>0.010020</td>\n","      <td>0.723160</td>\n","      <td>0.068595</td>\n","      <td>19.300231</td>\n","      <td>0.005677</td>\n","      <td>...</td>\n","      <td>0.682909</td>\n","      <td>0.689504</td>\n","      <td>0.677206</td>\n","      <td>0.692105</td>\n","      <td>0.662307</td>\n","      <td>0.689504</td>\n","      <td>0.966600</td>\n","      <td>0.673108</td>\n","      <td>7.179743</td>\n","      <td>no big change</td>\n","    </tr>\n","    <tr>\n","      <th>2199</th>\n","      <td>0.674110</td>\n","      <td>0.676227</td>\n","      <td>0.672440</td>\n","      <td>0.676004</td>\n","      <td>0.312048</td>\n","      <td>0.010509</td>\n","      <td>0.755154</td>\n","      <td>0.068595</td>\n","      <td>21.857938</td>\n","      <td>0.008792</td>\n","      <td>...</td>\n","      <td>0.682505</td>\n","      <td>0.689504</td>\n","      <td>0.677414</td>\n","      <td>0.691979</td>\n","      <td>0.662849</td>\n","      <td>0.689504</td>\n","      <td>0.896525</td>\n","      <td>0.674333</td>\n","      <td>7.179743</td>\n","      <td>increase</td>\n","    </tr>\n","    <tr>\n","      <th>2200</th>\n","      <td>0.675725</td>\n","      <td>0.675837</td>\n","      <td>0.668820</td>\n","      <td>0.669321</td>\n","      <td>0.279230</td>\n","      <td>0.008306</td>\n","      <td>0.536443</td>\n","      <td>0.068595</td>\n","      <td>18.491048</td>\n","      <td>0.003247</td>\n","      <td>...</td>\n","      <td>0.682505</td>\n","      <td>0.689504</td>\n","      <td>0.677475</td>\n","      <td>0.692413</td>\n","      <td>0.662537</td>\n","      <td>0.689504</td>\n","      <td>0.925453</td>\n","      <td>0.672328</td>\n","      <td>7.535366</td>\n","      <td>decrease</td>\n","    </tr>\n","    <tr>\n","      <th>2201</th>\n","      <td>0.669293</td>\n","      <td>0.671326</td>\n","      <td>0.662973</td>\n","      <td>0.664198</td>\n","      <td>0.552933</td>\n","      <td>0.005024</td>\n","      <td>0.362143</td>\n","      <td>0.068595</td>\n","      <td>15.904361</td>\n","      <td>-0.000906</td>\n","      <td>...</td>\n","      <td>0.679735</td>\n","      <td>0.689504</td>\n","      <td>0.677201</td>\n","      <td>0.691448</td>\n","      <td>0.662953</td>\n","      <td>0.689504</td>\n","      <td>0.977753</td>\n","      <td>0.667149</td>\n","      <td>7.707911</td>\n","      <td>decrease</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows Ã— 101 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c3649a63-f632-40b7-a026-da6a6de379ad')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-c3649a63-f632-40b7-a026-da6a6de379ad button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-c3649a63-f632-40b7-a026-da6a6de379ad');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":3}],"source":["#Last 5 data points of the first stock\n","print(f'Last 5 datapoints of the first stock among 2000 stocks')\n","stock_len = 2201\n","train_data.iloc[stock_len-5: stock_len] #To do: Once the concatenated file is ready."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sTG7-QUDYpcC"},"outputs":[],"source":["import torch\n","from torch.utils.data import DataLoader, Dataset, TensorDataset\n","import multiprocessing\n","\n","class MyDataset(Dataset):\n","    def __init__(self, df, stock_len, seq_length):\n","        self.X = []\n","        self.y = []\n","        \n","        labels = df.iloc[:, -1].values # Extract labels from the last column\n","        cnt = len(labels)\n","        \n","        df = df.iloc[:, :-1] # Remove labels column from the DataFrame        \n","        values = torch.tensor(df.values) # Convert DataFrame to tensor\n","        \n","        # Create input/output sequences\n","        while cnt != 0:\n","          for i in range(seq_length, stock_len):\n","            self.X.append(values[i-seq_length:i, :])\n","            self.y.append(labels[i])\n","          cnt -= stock_len\n","        \n","    def __getitem__(self, idx):\n","        return self.X[idx], self.y[idx]\n","    \n","    def __len__(self):\n","        return len(self.X)\n","\n","def data_generator(train_data, stock_len, seq_length, batch_size, num_workers):\n","    train_dataset = MyDataset(train_data, stock_len, seq_length)\n","    \n","    # Create DataLoader\n","    # Optimzation 1: Dataset and Dataloaders for batch processing\n","    # Optimization 2: (num_of_workers, pin_memory(GPU specific))    \n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)\n","\n","    for X_batch, y_batch in train_loader:\n","        # Convert labels to tensor\n","        y_train = np.array(y_batch)\n","        labels_encoded = torch.zeros((len(y_train), 3), dtype=torch.float32)\n","        labels_encoded[y_train == 'increase', 2] = 1\n","        labels_encoded[y_train == 'no big change', 1] = 1\n","        labels_encoded[y_train == 'decrease', 0] = 1        \n","        y_train_tensor = torch.tensor(labels_encoded, dtype=torch.float32).clone().detach()\n","\n","        yield X_batch, y_train_tensor\n","\n","    # Free up memory\n","    del train_dataset, train_loader\n","    del labels_encoded\n","    del y_train, X_batch, y_batch, y_train_tensor\n","\n","def prepare_train_data(train_data = None, stock_len=2201, seq_length = 100, batch_size = 32):\n","  num_workers=multiprocessing.cpu_count() #parallel computing\n","\n","  # Optimization 4 (Using data generator)\n","  generator = data_generator(train_data, stock_len, seq_length, batch_size, num_workers) \n","\n","  return generator"]},{"cell_type":"code","source":[],"metadata":{"id":"E94m4BMohhuK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["num_layers_FC = ([1]*5) + ([2]*5)\n","num_layers_FC.reverse()\n","hidden_dim_LSTM = [i for i in range(21, 31)]\n","hidden_dim_LSTM.reverse()\n","params_dict = {\"input_dim\": [100]*10, \n","               \"hidden_dim_FC\": [i for i in range(21, 31)],\n","               \"output_dim\": [3]*10, \n","               \"num_layers_LSTM\":([1]*5) + ([2]*5), \n","               \"learning rate\":[0.001, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09], \n","               \"num_epochs\": [i for i in range(10, 21)],\n","               \"model_id\":[1, 2, 3, 4, 5, 6, 7, 8, 9, 10] }\n","params_dict[\"num_layers_FC\"] = num_layers_FC\n","params_dict[\"hidden_dim_LSTM\"] = hidden_dim_LSTM "],"metadata":{"id":"OLqIijCujhyq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Necessary Imports\n","import torch\n","import torch.nn as nn\n","import torch.nn.init as init\n","from torch.utils.data import DataLoader, TensorDataset\n","from sklearn.metrics import accuracy_score, precision_score\n","from tqdm import tqdm"],"metadata":{"id":"S3hKMyhIO-CQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Inw1vSq6mTI7","colab":{"base_uri":"https://localhost:8080/","height":450},"outputId":"9b866d2e-009c-4e17-c48c-494eefab8b27","executionInfo":{"status":"error","timestamp":1683249926966,"user_tz":240,"elapsed":6638,"user":{"displayName":"Praneeth","userId":"13740106769956375743"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Model no 0\n"]},{"output_type":"stream","name":"stderr","text":["0it [00:06, ?it/s]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-7ff456a4ffd3>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    134\u001b[0m   \u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_train_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstocks_500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2201\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;31m#------------------------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m   \u001b[0mtrain_model1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-7-7ff456a4ffd3>\u001b[0m in \u001b[0;36mtrain_model1\u001b[0;34m(batch_generator, model_id, input_dim, learning_rate, num_epochs, hidden_dim_LSTM, output_dim)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;31m# Iterate over batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m                 \u001b[0;31m# Move data to device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-3-db319c480757>\u001b[0m in \u001b[0;36mdata_generator\u001b[0;34m(train_data, stock_len, seq_length, batch_size, num_workers)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdata_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstock_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMyDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstock_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m# Create DataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-3-db319c480757>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, df, stock_len, seq_length)\u001b[0m\n\u001b[1;32m     18\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstock_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mseq_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m           \u001b[0mcnt\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mstock_len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/arrays/_mixins.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ndarray\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_backing_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/arrays/categorical.py\u001b[0m in \u001b[0;36m_box_func\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m   2069\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2070\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_box_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2071\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2072\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNaN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2073\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategories\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["#num_layers = 1\n","#nn.dropout(p = 0.2)\n","for itr in range(0, 10):\n","  class LSTM1(nn.Module):\n","    def __init__(self, input_dim=params_dict[\"input_dim\"][itr], \n","                 hidden_dim_LSTM=params_dict[\"hidden_dim_LSTM\"][itr],\n","                 hidden_dim_FC=params_dict[\"hidden_dim_FC\"][itr],\n","                 output_dim=params_dict[\"output_dim\"][itr],\n","                 num_LSTM_layers=params_dict[\"num_layers_LSTM\"][itr],\n","                 num_layers_FC=params_dict[\"num_layers_FC\"][itr]):\n","        \n","          super(LSTM1, self).__init__()\n","          self.lstm = nn.LSTM(input_dim, hidden_dim_LSTM, num_layers=num_LSTM_layers, batch_first=True) #num_layers = 2\n","          self.dropout = nn.Dropout(p=0.2)\n","          self.fc = nn.Linear(hidden_dim_LSTM, output_dim)\n","          self.softmax = nn.Softmax(dim=1)\n","          self.num_LSTM_layers = num_LSTM_layers\n","          self.hidden_dim_LSTM = hidden_dim_LSTM \n","          \n","          # Use Xavier initialization for weights\n","          init.xavier_uniform_(self.lstm.weight_ih_l0)\n","          init.orthogonal_(self.lstm.weight_hh_l0)\n","          init.constant_(self.lstm.bias_ih_l0, 0.0)\n","          init.constant_(self.lstm.bias_hh_l0, 0.0)\n","          init.xavier_uniform_(self.fc.weight)\n","          init.constant_(self.fc.bias, 0.0)\n","\n","    def forward(self, x):\n","        h0 = torch.zeros(self.num_LSTM_layers, x.size(0), self.hidden_dim_LSTM).requires_grad_().to(device)\n","        c0 = torch.zeros(self.num_LSTM_layers, x.size(0), self.hidden_dim_LSTM).requires_grad_().to(device)\n","        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n","        out = self.dropout(out)\n","        out = self.fc(out[:, -1, :])\n","        out = out.view(-1, 3)\n","        out = self.softmax(out)\n","        return out\n","  # Check if CUDA is available\n","  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","#--------------------------------------------------------------------------------------------------------------------------------------------  \n","  def train_model1(batch_generator, model_id=params_dict[\"model_id\"][itr], \n","                input_dim=params_dict[\"input_dim\"][itr], \n","                learning_rate=params_dict[\"learning rate\"][itr], \n","                num_epochs=params_dict[\"num_epochs\"][itr], \n","                hidden_dim_LSTM=params_dict[\"hidden_dim_LSTM\"][itr],\n","                output_dim=params_dict[\"output_dim\"][itr]):\n","        # Evaluate each model for 10 epochs\n","        # Initialize the model\n","        learning_rate = learning_rate\n","        num_epochs = num_epochs\n","        input_dim = input_dim\n","        hidden_dim_LSTM = hidden_dim_LSTM\n","        # output_dim = y_train_tensor.shape[1]\n","        output_dim = 3\n","\n","        # Define the loss function and optimizer\n","        criterion = nn.CrossEntropyLoss()  \n","\n","        # Initialize the model\n","        print('Model no', model_id)\n","        model = LSTM1(input_dim, hidden_dim_LSTM, output_dim).to(device)\n","\n","        # Define the optimizer and scheduler for the current model\n","        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n","\n","        # Checkpointing parameters for the current model\n","        checkpoint_interval = 1\n","        checkpoint_file = f'lstm_task_3_checkpoint_{model_id}.pth'\n","\n","        # Define early stopping parameters\n","        best_loss = float('inf')\n","        early_stop_counter = 0\n","        early_stop_patience = 5\n","\n","        # Train the current model for 10 epochs\n","        for epoch in range(num_epochs):\n","            # Set model to train mode\n","            model.train()\n","            # model.double()\n","\n","            # Iterate over batches\n","            for x_batch, y_batch in tqdm(generator):\n","                # Move data to device\n","                x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n","                # Cast x_batch to float32\n","                x_batch = x_batch.float()\n","                print(x_batch.shape)\n","\n","                # Forward pass\n","                outputs = model(x_batch)\n","                loss = criterion(outputs, y_batch)\n","\n","                # Backward and optimize\n","                optimizer.zero_grad()\n","                loss.backward()\n","                optimizer.step()\n","\n","            # Print the loss for every 10 epochs\n","            if (epoch + 1) % 10 == 0:\n","                print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch + 1, num_epochs, loss.item()))\n","\n","            # Check if current model has reached early stopping criteria\n","            print(loss.item())\n","            if loss.item() < best_loss:\n","                best_loss = loss.item()\n","                early_stop_counter = 0\n","            else:\n","                early_stop_counter += 1\n","\n","            if early_stop_counter >= early_stop_patience:\n","                print(f\"Training for model {itr} stopped early at epoch {epoch+1} due to early stopping\")\n","                break\n","\n","            # Save checkpoint at regular intervals\n","            if (epoch + 1) % checkpoint_interval == 0:\n","                torch.save({\n","                    'epoch': epoch + 1,\n","                    'model_state_dict': model.state_dict(),\n","                    'optimizer_state_dict': optimizer.state_dict(),\n","                    'loss': loss.item(),\n","                }, checkpoint_file)\n","\n","            # Step the scheduler\n","            scheduler.step()\n","\n","        # Delete variables to free up memory\n","        del model, optimizer, scheduler\n","#------------------------------------------------------------------------------------------------------------------------------------------------------------\n","  # Empty the cache to free up GPU memory\n","  torch.cuda.empty_cache()\n","  seq_length = 100 # Define sequence length\n","  batch_size = 32 # Create data loader\n","  stocks_500 = 2201*500\n","  generator = prepare_train_data(train_data.iloc[:stocks_500, :], 2201, seq_length, batch_size)\n","#------------------------------------------------------------------------------------------------------------------------------------------------------------\n","  train_model1(generator, itr)"]},{"cell_type":"code","source":["def print_table(metrics):\n","    header = ['Model', 'Train', '', '', 'Validation', '', '', '', '']\n","    subheader = ['', '', 'Precision', 'Accuracy', '% Positive', 'Precision', 'Accuracy', '% Positive']\n","    print(\" {:<10} {:<10} {:<14} {:<10} {:<10} {:<14} {:<14} {:<14}\".format(*header))\n","    print(\"{:<10} {:<0} {:<10} {:<10} {:<14} {:<10} {:<10} {:<14}\".format(*subheader))\n","\n","    for i in range(len(metrics)):\n","        row =[i+1] + [f\"{val:.4f}\" for val in metrics[i]['train']] + [f\"{val:.4f}\" for val in metrics[i]['val']]\n","        print(\"{:<11} {:<10} {:<10} {:<14} {:<10} {:<10} {:<14}\".format(*row))\n","    return"],"metadata":{"id":"cprmFKbZA68O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["metrics = []\n","for itr2 in range(0, 10):\n","  class LSTM1(nn.Module):\n","    def __init__(self, input_dim=params_dict[\"input_dim\"][itr2], \n","                 hidden_dim_LSTM=params_dict[\"hidden_dim_LSTM\"][itr2],\n","                 hidden_dim_FC=params_dict[\"hidden_dim_FC\"][itr2],\n","                 output_dim=params_dict[\"output_dim\"][itr2],\n","                 num_LSTM_layers=params_dict[\"num_layers_LSTM\"][itr2],\n","                 num_layers_FC=params_dict[\"num_layers_FC\"][itr2]):\n","        \n","          super(LSTM1, self).__init__()\n","          self.lstm = nn.LSTM(input_dim, hidden_dim_LSTM, num_layers=num_LSTM_layers, batch_first=True) #num_layers = 2\n","          self.dropout = nn.Dropout(p=0.2)\n","          self.fc = nn.Linear(hidden_dim_LSTM, output_dim)\n","          self.softmax = nn.Softmax(dim=1)\n","          self.num_LSTM_layers = num_LSTM_layers\n","          self.hidden_dim_LSTM = hidden_dim_LSTM \n","          \n","          # Use Xavier initialization for weights\n","          init.xavier_uniform_(self.lstm.weight_ih_l0)\n","          init.orthogonal_(self.lstm.weight_hh_l0)\n","          init.constant_(self.lstm.bias_ih_l0, 0.0)\n","          init.constant_(self.lstm.bias_hh_l0, 0.0)\n","          init.xavier_uniform_(self.fc.weight)\n","          init.constant_(self.fc.bias, 0.0)\n","\n","    def forward(self, x):\n","        h0 = torch.zeros(self.num_LSTM_layers, x.size(0), self.hidden_dim_LSTM).requires_grad_().to(device)\n","        c0 = torch.zeros(self.num_LSTM_layers, x.size(0), self.hidden_dim_LSTM).requires_grad_().to(device)\n","        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n","        out = self.dropout(out)\n","        out = self.fc(out[:, -1, :])\n","        out = out.view(-1, 3)\n","        out = self.softmax(out)\n","        return out\n","  # Check if CUDA is available\n","  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","#------------------------------------------------------------------------------------------------------------------------------------------  \n","  def perform_validation1(num_models=1, file_desc=itr2, data_generator=None):\n","    # Evaluate each model on the primary training set and the validation set  \n","    checkpoint_file = f'lstm_task_3_checkpoint_{file_desc}.pth' # Load the trained model from the checkpoint file\n","    checkpoint = torch.load(checkpoint_file, map_location=torch.device('cpu'))  \n","    model = LSTM1(params_dict[\"input_dim\"][itr2], params_dict[\"hidden_dim_LSTM\"][itr2], 3).to(device)\n","    model.load_state_dict(checkpoint['model_state_dict'])\n","\n","    # Evaluate the current model on the passed data  \n","    result_pred_labels = []  \n","    precisions = []\n","    accuracies = []\n","    for X_data, y_data in data_generator:        \n","      with torch.no_grad():\n","        X_data = X_data.float()\n","        outputs = model.forward(X_data.to(device))\n","\n","      # Convert predicted and true labels to one-hot encodings\n","      predicted_labels = torch.argmax(outputs, dim=1).to(device)\n","      true_labels = torch.argmax(y_data, dim=1).to(device)\n","\n","      # Calculate precision for each class    \n","      for i in range(3):\n","        if i == 2: # positive class\n","            true_positives = torch.sum((predicted_labels == i) & (true_labels == i))\n","            false_positives = torch.sum((predicted_labels == i) & (true_labels != 2))\n","            precision = true_positives.float() / (true_positives + false_positives).float()            \n","            accuracies.append(torch.mean((predicted_labels == true_labels).float() * (true_labels == i).float()))\n","        else: # negative class\n","            true_negatives = torch.sum((predicted_labels == i) & (true_labels == i) & (true_labels != 2))\n","            false_positives = torch.sum((predicted_labels == i) & (true_labels != i) & (true_labels != 2))\n","            precision = true_negatives.float() / (true_negatives + false_positives).float()\n","            accuracies.append(torch.mean((predicted_labels == true_labels).float() * (true_labels != i).float()))\n","        if not torch.isnan(precision):\n","          precisions.append(precision)\n","\n","    # Calculate average precision and accuracy\n","    avg_precision = torch.mean(torch.tensor(precisions))\n","    avg_accuracy = torch.mean(torch.tensor(accuracies))\n","\n","    # Calculate percentage of positive predictions\n","    percent_positive = torch.mean((predicted_labels == 2).float())\n","    \n","    # Free Memory  \n","    del model, outputs, X_data, y_data, true_labels, predicted_labels, precisions, accuracies, true_negatives, false_positives, precision\n","    del result_pred_labels\n","    torch.cuda.empty_cache()\n","    return [avg_precision, avg_accuracy, percent_positive]\n","#-----------------------------------------------------------------------------------------------------------------------------------------------  \n","  start = 0\n","  test_data = train_data.iloc[500*2201:599*2201, :]\n","  generator = prepare_train_data(test_data, 2201, seq_length=100, batch_size=1000)\n","#----------------------------------------------------------------------------------------------------------------------------------------------------\n","  metrics.append(perform_validation1(num_models=1, file_desc=itr2, data_generator=generator))\n"],"metadata":{"id":"3NWUpleQQOQP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683254727740,"user_tz":240,"elapsed":938665,"user":{"displayName":"Praneeth","userId":"13740106769956375743"}},"outputId":"393b59a8-e6c5-4316-d20d-c84a124bea02"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-4-db319c480757>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_train_tensor = torch.tensor(labels_encoded, dtype=torch.float32).clone().detach()\n"]}]},{"cell_type":"code","source":["metrics"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":171},"id":"OlKOJd0qoiPv","executionInfo":{"status":"error","timestamp":1683255478163,"user_tz":240,"elapsed":259,"user":{"displayName":"Yash Oswal","userId":"08926553451935908326"}},"outputId":"8d6e6323-8162-41bf-d3bc-4f9663452b4e"},"execution_count":3,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-71cacc06bb91>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'metrics' is not defined"]}]},{"cell_type":"code","source":["def perform_validation1(num_models=1, file_desc=None, data_generator=None, param_dict=None):\n","  # Evaluate each model on the primary training set and the validation set  \n","  checkpoint_file = f'lstm_task_3_checkpoint_{file_desc}.pth' # Load the trained model from the checkpoint file\n","  checkpoint = torch.load(checkpoint_file, map_location=torch.device('cpu'))  \n","  model = LSTM1(param_dict[\"input_dim\"], param_dict[\"hidden_dim_LSTM\"], 3).to(device)\n","  model.load_state_dict(checkpoint['model_state_dict'])\n","\n","  # Evaluate the current model on the passed data  \n","  result_pred_labels = []  \n","  precisions = []\n","  accuracies = []\n","  for X_data, y_data in data_generator:        \n","    with torch.no_grad():\n","      X_data = X_data.float()\n","      outputs = model.forward(X_data.to(device))\n","\n","    # Convert predicted and true labels to one-hot encodings\n","    predicted_labels = torch.argmax(outputs, dim=1).to(device)\n","    true_labels = torch.argmax(y_data, dim=1).to(device)\n","\n","    # Calculate precision for each class    \n","    for i in range(3):\n","      if i == 2: # positive class\n","          true_positives = torch.sum((predicted_labels == i) & (true_labels == i))\n","          false_positives = torch.sum((predicted_labels == i) & (true_labels != 2))\n","          precision = true_positives.float() / (true_positives + false_positives).float()\n","          accuracies.append(torch.mean((predicted_labels == true_labels).float() * (true_labels == i).float()))\n","      else: # negative class\n","          true_negatives = torch.sum((predicted_labels == i) & (true_labels == i) & (true_labels != 2))\n","          false_positives = torch.sum((predicted_labels == i) & (true_labels != i) & (true_labels != 2))\n","          precision = true_negatives.float() / (true_negatives + false_positives).float()\n","          accuracies.append(torch.mean((predicted_labels == true_labels).float() * (true_labels != i).float()))\n","      precisions.append(precision)\n","\n","  # Calculate average precision and accuracy\n","  avg_precision = torch.mean(torch.tensor(precisions))\n","  avg_accuracy = torch.mean(torch.tensor(accuracies))\n","\n","  # Calculate percentage of positive predictions\n","  percent_positive = torch.mean((predicted_labels == 2).float())\n","  \n","  # Free Memory  \n","  del model, outputs, X_data, y_data, true_labels, predicted_labels, precisions, accuracies, true_negatives, false_positives, precision\n","  del result_pred_labels\n","  torch.cuda.empty_cache()\n","  return [avg_precision, avg_accuracy, percent_positive]"],"metadata":{"id":"3c4ytBwpdyuv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def print_table(metrics):\n","    header = ['Model', 'Train', '', '', 'Validation', '', '', '', '']\n","    subheader = ['', '', 'Precision', 'Accuracy', '% Positive', 'Precision', 'Accuracy', '% Positive']\n","    print(\" {:<10} {:<10} {:<14} {:<10} {:<10} {:<14} {:<14} {:<14}\".format(*header))\n","    print(\"{:<10} {:<0} {:<10} {:<10} {:<14} {:<10} {:<10} {:<14}\".format(*subheader))\n","\n","    for i in range(len(metrics)):\n","        row =[i+1] + [f\"{val:.4f}\" for val in metrics[i]['train']] + [f\"{val:.4f}\" for val in metrics[i]['val']]\n","        print(\"{:<11} {:<10} {:<10} {:<14} {:<10} {:<10} {:<14}\".format(*row))\n","    return"],"metadata":{"id":"BfgACKiieoPi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Concatenate tensors of empty(Provding early shape can provide performance improvement)\n","start = 0\n","test_data = train_data.iloc[:100]\n","generator = prepare_train_data(test_data, 2201, seq_length, batch_size)"],"metadata":{"id":"t05balygblHl"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V4nZ9aNGEKex"},"outputs":[],"source":["# X_val_subsets, y_val_subsets = create_subset(X_test_tensor, y_test_tensor, num_models)\n","metrics = perform_validation1(num_models=1, file_desc=None, data_generator=None, param_dict=None)\n","print_table(metrics)"]},{"cell_type":"code","source":["metrics"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oCX_5cV0lefK","executionInfo":{"status":"ok","timestamp":1683116914438,"user_tz":240,"elapsed":187,"user":{"displayName":"Pran En","userId":"14838666787094319667"}},"outputId":"384a878e-fff3-4d7a-d028-75007036ba82"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'train': [], 'val': [tensor(nan), tensor(0.1481), tensor(0.2778)]}]"]},"metadata":{},"execution_count":42}]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1vTyc_3FgJt0iAUJWv5aRK8FXcEH6gmLT","timestamp":1683129493039},{"file_id":"1OVIwecTeWT8mV-MLDIB6PTY9XxYv7P9m","timestamp":1683129317616},{"file_id":"11qohwNbxcNBvJBoKMvpJrtZy2LNWpc95","timestamp":1682809990606},{"file_id":"1W2sswuGKRxM4PCb83Zm2BbNnaoZPv4tk","timestamp":1682310416896}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}