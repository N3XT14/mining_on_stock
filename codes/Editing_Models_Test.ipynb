{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"84AtUsH0bo3w","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684381201637,"user_tz":240,"elapsed":7,"user":{"displayName":"Yash Oswal","userId":"08926553451935908326"}},"outputId":"9ccabf48-4525-4350-d66b-4a45118bded1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["#Necessary Imports\n","# !pip install ta\n","import numpy as np\n","import pandas as pd\n","import os\n","import pickle\n","import torch\n","# import ta\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","#Data Source Location\n","os.chdir(\"/content/drive/My Drive/mining-on-stock\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ckORrrbKbssR"},"outputs":[],"source":["#Load Feature Engineered Stock dataset: 100 Features including labels\n","with open('data_with_features_clean_train.pkl', 'rb') as train_file: #To do: Change file name.\n","  train_data = pickle.load(train_file)"]},{"cell_type":"code","source":["len(train_data.columns)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2OyUXr9-rlDA","executionInfo":{"status":"ok","timestamp":1683126507260,"user_tz":240,"elapsed":37,"user":{"displayName":"Praneeth","userId":"13740106769956375743"}},"outputId":"1ece9550-5414-4359-90ce-986c3c7b4912"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["101"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cBVXZ03BYD91","colab":{"base_uri":"https://localhost:8080/","height":369},"executionInfo":{"status":"ok","timestamp":1683126507261,"user_tz":240,"elapsed":34,"user":{"displayName":"Praneeth","userId":"13740106769956375743"}},"outputId":"db4837c0-68fd-400b-a9a9-25eb0a5234db"},"outputs":[{"output_type":"stream","name":"stdout","text":["Last 5 datapoints of the first stock among 2000 stocks\n"]},{"output_type":"execute_result","data":{"text/plain":["          Open      High       Low     Close    Volume  \\\n","2197  0.680849  0.683633  0.672997  0.674055  0.351048   \n","2198  0.674389  0.674890  0.671326  0.674055  0.143069   \n","2199  0.674110  0.676227  0.672440  0.676004  0.312048   \n","2200  0.675725  0.675837  0.668820  0.669321  0.279230   \n","2201  0.669293  0.671326  0.662973  0.664198  0.552933   \n","\n","      awesome_oscillator (AO)  bollinger_percent_b (percent_b)  cfo (cfo)  \\\n","2197                 0.010157                         0.744441   0.068595   \n","2198                 0.010020                         0.723160   0.068595   \n","2199                 0.010509                         0.755154   0.068595   \n","2200                 0.008306                         0.536443   0.068595   \n","2201                 0.005024                         0.362143   0.068595   \n","\n","      cmo (cmo)  detrended_price_oscillator (dpo)  ...  \\\n","2197  21.168686                          0.004813  ...   \n","2198  19.300231                          0.005677  ...   \n","2199  21.857938                          0.008792  ...   \n","2200  18.491048                          0.003247  ...   \n","2201  15.904361                         -0.000906  ...   \n","\n","      ichimoku_clouds (senkou_span_a)  ichimoku_clouds (chikou_span)  \\\n","2197                         0.683299                       0.689504   \n","2198                         0.682909                       0.689504   \n","2199                         0.682505                       0.689504   \n","2200                         0.682505                       0.689504   \n","2201                         0.679735                       0.689504   \n","\n","      keltner_channel (Keltner Center)  keltner_channel (Keltner Upper)  \\\n","2197                          0.677062                         0.692473   \n","2198                          0.677206                         0.692105   \n","2199                          0.677414                         0.691979   \n","2200                          0.677475                         0.692413   \n","2201                          0.677201                         0.691448   \n","\n","      keltner_channel (Keltner Lower)  linear_reg_forecast (LRF)  \\\n","2197                         0.661650                   0.689504   \n","2198                         0.662307                   0.689504   \n","2199                         0.662849                   0.689504   \n","2200                         0.662537                   0.689504   \n","2201                         0.662953                   0.689504   \n","\n","      mass_index (Mass_Index)  median_price (Median Price)  \\\n","2197                 1.080827                     0.678315   \n","2198                 0.966600                     0.673108   \n","2199                 0.896525                     0.674333   \n","2200                 0.925453                     0.672328   \n","2201                 0.977753                     0.667149   \n","\n","      money_flow_index (Money Flow Index)          Label  \n","2197                             7.843752       decrease  \n","2198                             7.179743  no big change  \n","2199                             7.179743       increase  \n","2200                             7.535366       decrease  \n","2201                             7.707911       decrease  \n","\n","[5 rows x 101 columns]"],"text/html":["\n","  <div id=\"df-b25e18e3-4d7c-493a-9bf2-dc4a2d263cc9\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Open</th>\n","      <th>High</th>\n","      <th>Low</th>\n","      <th>Close</th>\n","      <th>Volume</th>\n","      <th>awesome_oscillator (AO)</th>\n","      <th>bollinger_percent_b (percent_b)</th>\n","      <th>cfo (cfo)</th>\n","      <th>cmo (cmo)</th>\n","      <th>detrended_price_oscillator (dpo)</th>\n","      <th>...</th>\n","      <th>ichimoku_clouds (senkou_span_a)</th>\n","      <th>ichimoku_clouds (chikou_span)</th>\n","      <th>keltner_channel (Keltner Center)</th>\n","      <th>keltner_channel (Keltner Upper)</th>\n","      <th>keltner_channel (Keltner Lower)</th>\n","      <th>linear_reg_forecast (LRF)</th>\n","      <th>mass_index (Mass_Index)</th>\n","      <th>median_price (Median Price)</th>\n","      <th>money_flow_index (Money Flow Index)</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2197</th>\n","      <td>0.680849</td>\n","      <td>0.683633</td>\n","      <td>0.672997</td>\n","      <td>0.674055</td>\n","      <td>0.351048</td>\n","      <td>0.010157</td>\n","      <td>0.744441</td>\n","      <td>0.068595</td>\n","      <td>21.168686</td>\n","      <td>0.004813</td>\n","      <td>...</td>\n","      <td>0.683299</td>\n","      <td>0.689504</td>\n","      <td>0.677062</td>\n","      <td>0.692473</td>\n","      <td>0.661650</td>\n","      <td>0.689504</td>\n","      <td>1.080827</td>\n","      <td>0.678315</td>\n","      <td>7.843752</td>\n","      <td>decrease</td>\n","    </tr>\n","    <tr>\n","      <th>2198</th>\n","      <td>0.674389</td>\n","      <td>0.674890</td>\n","      <td>0.671326</td>\n","      <td>0.674055</td>\n","      <td>0.143069</td>\n","      <td>0.010020</td>\n","      <td>0.723160</td>\n","      <td>0.068595</td>\n","      <td>19.300231</td>\n","      <td>0.005677</td>\n","      <td>...</td>\n","      <td>0.682909</td>\n","      <td>0.689504</td>\n","      <td>0.677206</td>\n","      <td>0.692105</td>\n","      <td>0.662307</td>\n","      <td>0.689504</td>\n","      <td>0.966600</td>\n","      <td>0.673108</td>\n","      <td>7.179743</td>\n","      <td>no big change</td>\n","    </tr>\n","    <tr>\n","      <th>2199</th>\n","      <td>0.674110</td>\n","      <td>0.676227</td>\n","      <td>0.672440</td>\n","      <td>0.676004</td>\n","      <td>0.312048</td>\n","      <td>0.010509</td>\n","      <td>0.755154</td>\n","      <td>0.068595</td>\n","      <td>21.857938</td>\n","      <td>0.008792</td>\n","      <td>...</td>\n","      <td>0.682505</td>\n","      <td>0.689504</td>\n","      <td>0.677414</td>\n","      <td>0.691979</td>\n","      <td>0.662849</td>\n","      <td>0.689504</td>\n","      <td>0.896525</td>\n","      <td>0.674333</td>\n","      <td>7.179743</td>\n","      <td>increase</td>\n","    </tr>\n","    <tr>\n","      <th>2200</th>\n","      <td>0.675725</td>\n","      <td>0.675837</td>\n","      <td>0.668820</td>\n","      <td>0.669321</td>\n","      <td>0.279230</td>\n","      <td>0.008306</td>\n","      <td>0.536443</td>\n","      <td>0.068595</td>\n","      <td>18.491048</td>\n","      <td>0.003247</td>\n","      <td>...</td>\n","      <td>0.682505</td>\n","      <td>0.689504</td>\n","      <td>0.677475</td>\n","      <td>0.692413</td>\n","      <td>0.662537</td>\n","      <td>0.689504</td>\n","      <td>0.925453</td>\n","      <td>0.672328</td>\n","      <td>7.535366</td>\n","      <td>decrease</td>\n","    </tr>\n","    <tr>\n","      <th>2201</th>\n","      <td>0.669293</td>\n","      <td>0.671326</td>\n","      <td>0.662973</td>\n","      <td>0.664198</td>\n","      <td>0.552933</td>\n","      <td>0.005024</td>\n","      <td>0.362143</td>\n","      <td>0.068595</td>\n","      <td>15.904361</td>\n","      <td>-0.000906</td>\n","      <td>...</td>\n","      <td>0.679735</td>\n","      <td>0.689504</td>\n","      <td>0.677201</td>\n","      <td>0.691448</td>\n","      <td>0.662953</td>\n","      <td>0.689504</td>\n","      <td>0.977753</td>\n","      <td>0.667149</td>\n","      <td>7.707911</td>\n","      <td>decrease</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 101 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b25e18e3-4d7c-493a-9bf2-dc4a2d263cc9')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-b25e18e3-4d7c-493a-9bf2-dc4a2d263cc9 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-b25e18e3-4d7c-493a-9bf2-dc4a2d263cc9');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":4}],"source":["#Last 5 data points of the first stock\n","print(f'Last 5 datapoints of the first stock among 2000 stocks')\n","stock_len = 2201\n","train_data.iloc[stock_len-5: stock_len] #To do: Once the concatenated file is ready."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sTG7-QUDYpcC"},"outputs":[],"source":["import torch\n","from torch.utils.data import DataLoader, Dataset, TensorDataset\n","import multiprocessing\n","\n","class MyDataset(Dataset):\n","    def __init__(self, df, seq_length):\n","        self.X = []\n","        self.y = []\n","        \n","        labels = df.iloc[:, -1].values # Extract labels from the last column\n","        cnt = len(labels)\n","        \n","        df = df.iloc[:, :-1] # Remove labels column from the DataFrame        \n","        values = torch.tensor(df.values) # Convert DataFrame to tensor\n","        stock_len = 2201\n","        # Create input/output sequences\n","        while cnt != 0:\n","          for i in range(seq_length, stock_len):\n","            self.X.append(values[i-seq_length:i, :])\n","            self.y.append(labels[i])\n","          cnt -= 2201\n","    \n","    def __getitem__(self, idx):\n","        return self.X[idx], self.y[idx]\n","    \n","    def __len__(self):\n","        return len(self.X)\n","\n","def data_generator(train_data, seq_length, batch_size, num_workers):\n","    train_dataset = MyDataset(train_data, seq_length)    \n","    \n","    # Create DataLoader\n","    # Optimzation 1: Dataset and Dataloaders for batch processing\n","    # Optimization 2: (num_of_workers, pin_memory(GPU specific))    \n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n","\n","    for X_batch, y_batch in train_loader:\n","        # Convert labels to tensor\n","        y_train = np.array(y_batch)\n","        labels_encoded = torch.zeros((len(y_train), 3), dtype=torch.float32)\n","        labels_encoded[y_train == 'increase', 2] = 1\n","        labels_encoded[y_train == 'no big change', 1] = 1\n","        labels_encoded[y_train == 'decrease', 0] = 1\n","        y_train_tensor = torch.tensor(labels_encoded).float().clone().detach()\n","\n","        yield X_batch, y_train_tensor\n","\n","    # Free up memory\n","    del train_dataset, train_loader\n","    del labels_encoded\n","    del y_train, X_batch, y_batch, y_train_tensor\n","\n","def prepare_train_data(train_data = None, seq_length = 100, batch_size = 32):\n","  num_workers=multiprocessing.cpu_count() #parallel computing\n","\n","  # Optimization 4 (Using data generator)\n","  generator = data_generator(train_data, seq_length, batch_size, num_workers) \n","\n","  return generator"]},{"cell_type":"code","source":["train_data[:2201]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":574},"id":"4uHFiQaUEq9M","executionInfo":{"status":"ok","timestamp":1683126507261,"user_tz":240,"elapsed":11,"user":{"displayName":"Praneeth","userId":"13740106769956375743"}},"outputId":"6ba27a2c-cd0e-4142-fdcc-268af73a32ec"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["          Open      High       Low     Close    Volume  \\\n","1     0.672106  0.674597  0.670546  0.672106  0.208023   \n","2     0.672106  0.678621  0.671827  0.676282  0.142405   \n","3     0.676338  0.677340  0.672384  0.673498  0.146400   \n","4     0.673442  0.676004  0.672997  0.675892  0.116960   \n","5     0.675892  0.676115  0.673609  0.674890  0.205266   \n","...        ...       ...       ...       ...       ...   \n","2197  0.680849  0.683633  0.672997  0.674055  0.351048   \n","2198  0.674389  0.674890  0.671326  0.674055  0.143069   \n","2199  0.674110  0.676227  0.672440  0.676004  0.312048   \n","2200  0.675725  0.675837  0.668820  0.669321  0.279230   \n","2201  0.669293  0.671326  0.662973  0.664198  0.552933   \n","\n","      awesome_oscillator (AO)  bollinger_percent_b (percent_b)  cfo (cfo)  \\\n","1                    0.005725                         0.464494   1.376252   \n","2                    0.005725                         0.464494   0.944498   \n","3                    0.005725                         0.464494   1.546220   \n","4                    0.005725                         0.464494   1.346294   \n","5                    0.005725                         0.464494   1.667214   \n","...                       ...                              ...        ...   \n","2197                 0.010157                         0.744441   0.068595   \n","2198                 0.010020                         0.723160   0.068595   \n","2199                 0.010509                         0.755154   0.068595   \n","2200                 0.008306                         0.536443   0.068595   \n","2201                 0.005024                         0.362143   0.068595   \n","\n","      cmo (cmo)  detrended_price_oscillator (dpo)  ...  \\\n","1     38.508723                          0.000000  ...   \n","2     38.508723                          0.000000  ...   \n","3     38.508723                          0.000000  ...   \n","4     38.508723                          0.000000  ...   \n","5     38.508723                          0.000000  ...   \n","...         ...                               ...  ...   \n","2197  21.168686                          0.004813  ...   \n","2198  19.300231                          0.005677  ...   \n","2199  21.857938                          0.008792  ...   \n","2200  18.491048                          0.003247  ...   \n","2201  15.904361                         -0.000906  ...   \n","\n","      ichimoku_clouds (senkou_span_a)  ichimoku_clouds (chikou_span)  \\\n","1                            0.684928                       0.689504   \n","2                            0.684928                       0.689504   \n","3                            0.684928                       0.689504   \n","4                            0.684928                       0.689504   \n","5                            0.684928                       0.689504   \n","...                               ...                            ...   \n","2197                         0.683299                       0.689504   \n","2198                         0.682909                       0.689504   \n","2199                         0.682505                       0.689504   \n","2200                         0.682505                       0.689504   \n","2201                         0.679735                       0.689504   \n","\n","      keltner_channel (Keltner Center)  keltner_channel (Keltner Upper)  \\\n","1                             0.679429                         0.695254   \n","2                             0.679482                         0.695254   \n","3                             0.679507                         0.695254   \n","4                             0.679506                         0.695254   \n","5                             0.679529                         0.695254   \n","...                                ...                              ...   \n","2197                          0.677062                         0.692473   \n","2198                          0.677206                         0.692105   \n","2199                          0.677414                         0.691979   \n","2200                          0.677475                         0.692413   \n","2201                          0.677201                         0.691448   \n","\n","      keltner_channel (Keltner Lower)  linear_reg_forecast (LRF)  \\\n","1                            0.674792                   0.689504   \n","2                            0.674792                   0.689504   \n","3                            0.674792                   0.689504   \n","4                            0.674792                   0.689504   \n","5                            0.674792                   0.689504   \n","...                               ...                        ...   \n","2197                         0.661650                   0.689504   \n","2198                         0.662307                   0.689504   \n","2199                         0.662849                   0.689504   \n","2200                         0.662537                   0.689504   \n","2201                         0.662953                   0.689504   \n","\n","      mass_index (Mass_Index)  median_price (Median Price)  \\\n","1                    1.004993                     0.672572   \n","2                    1.004993                     0.675224   \n","3                    1.004993                     0.674862   \n","4                    1.004993                     0.674500   \n","5                    1.004993                     0.674862   \n","...                       ...                          ...   \n","2197                 1.080827                     0.678315   \n","2198                 0.966600                     0.673108   \n","2199                 0.896525                     0.674333   \n","2200                 0.925453                     0.672328   \n","2201                 0.977753                     0.667149   \n","\n","      money_flow_index (Money Flow Index)          Label  \n","1                               27.384836  no big change  \n","2                               27.384836       increase  \n","3                               27.384836       decrease  \n","4                               27.384836       increase  \n","5                               27.384836  no big change  \n","...                                   ...            ...  \n","2197                             7.843752       decrease  \n","2198                             7.179743  no big change  \n","2199                             7.179743       increase  \n","2200                             7.535366       decrease  \n","2201                             7.707911       decrease  \n","\n","[2201 rows x 101 columns]"],"text/html":["\n","  <div id=\"df-52443c9f-8454-4d22-a9f2-4d07272efded\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Open</th>\n","      <th>High</th>\n","      <th>Low</th>\n","      <th>Close</th>\n","      <th>Volume</th>\n","      <th>awesome_oscillator (AO)</th>\n","      <th>bollinger_percent_b (percent_b)</th>\n","      <th>cfo (cfo)</th>\n","      <th>cmo (cmo)</th>\n","      <th>detrended_price_oscillator (dpo)</th>\n","      <th>...</th>\n","      <th>ichimoku_clouds (senkou_span_a)</th>\n","      <th>ichimoku_clouds (chikou_span)</th>\n","      <th>keltner_channel (Keltner Center)</th>\n","      <th>keltner_channel (Keltner Upper)</th>\n","      <th>keltner_channel (Keltner Lower)</th>\n","      <th>linear_reg_forecast (LRF)</th>\n","      <th>mass_index (Mass_Index)</th>\n","      <th>median_price (Median Price)</th>\n","      <th>money_flow_index (Money Flow Index)</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>0.672106</td>\n","      <td>0.674597</td>\n","      <td>0.670546</td>\n","      <td>0.672106</td>\n","      <td>0.208023</td>\n","      <td>0.005725</td>\n","      <td>0.464494</td>\n","      <td>1.376252</td>\n","      <td>38.508723</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.684928</td>\n","      <td>0.689504</td>\n","      <td>0.679429</td>\n","      <td>0.695254</td>\n","      <td>0.674792</td>\n","      <td>0.689504</td>\n","      <td>1.004993</td>\n","      <td>0.672572</td>\n","      <td>27.384836</td>\n","      <td>no big change</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.672106</td>\n","      <td>0.678621</td>\n","      <td>0.671827</td>\n","      <td>0.676282</td>\n","      <td>0.142405</td>\n","      <td>0.005725</td>\n","      <td>0.464494</td>\n","      <td>0.944498</td>\n","      <td>38.508723</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.684928</td>\n","      <td>0.689504</td>\n","      <td>0.679482</td>\n","      <td>0.695254</td>\n","      <td>0.674792</td>\n","      <td>0.689504</td>\n","      <td>1.004993</td>\n","      <td>0.675224</td>\n","      <td>27.384836</td>\n","      <td>increase</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.676338</td>\n","      <td>0.677340</td>\n","      <td>0.672384</td>\n","      <td>0.673498</td>\n","      <td>0.146400</td>\n","      <td>0.005725</td>\n","      <td>0.464494</td>\n","      <td>1.546220</td>\n","      <td>38.508723</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.684928</td>\n","      <td>0.689504</td>\n","      <td>0.679507</td>\n","      <td>0.695254</td>\n","      <td>0.674792</td>\n","      <td>0.689504</td>\n","      <td>1.004993</td>\n","      <td>0.674862</td>\n","      <td>27.384836</td>\n","      <td>decrease</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.673442</td>\n","      <td>0.676004</td>\n","      <td>0.672997</td>\n","      <td>0.675892</td>\n","      <td>0.116960</td>\n","      <td>0.005725</td>\n","      <td>0.464494</td>\n","      <td>1.346294</td>\n","      <td>38.508723</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.684928</td>\n","      <td>0.689504</td>\n","      <td>0.679506</td>\n","      <td>0.695254</td>\n","      <td>0.674792</td>\n","      <td>0.689504</td>\n","      <td>1.004993</td>\n","      <td>0.674500</td>\n","      <td>27.384836</td>\n","      <td>increase</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.675892</td>\n","      <td>0.676115</td>\n","      <td>0.673609</td>\n","      <td>0.674890</td>\n","      <td>0.205266</td>\n","      <td>0.005725</td>\n","      <td>0.464494</td>\n","      <td>1.667214</td>\n","      <td>38.508723</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.684928</td>\n","      <td>0.689504</td>\n","      <td>0.679529</td>\n","      <td>0.695254</td>\n","      <td>0.674792</td>\n","      <td>0.689504</td>\n","      <td>1.004993</td>\n","      <td>0.674862</td>\n","      <td>27.384836</td>\n","      <td>no big change</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2197</th>\n","      <td>0.680849</td>\n","      <td>0.683633</td>\n","      <td>0.672997</td>\n","      <td>0.674055</td>\n","      <td>0.351048</td>\n","      <td>0.010157</td>\n","      <td>0.744441</td>\n","      <td>0.068595</td>\n","      <td>21.168686</td>\n","      <td>0.004813</td>\n","      <td>...</td>\n","      <td>0.683299</td>\n","      <td>0.689504</td>\n","      <td>0.677062</td>\n","      <td>0.692473</td>\n","      <td>0.661650</td>\n","      <td>0.689504</td>\n","      <td>1.080827</td>\n","      <td>0.678315</td>\n","      <td>7.843752</td>\n","      <td>decrease</td>\n","    </tr>\n","    <tr>\n","      <th>2198</th>\n","      <td>0.674389</td>\n","      <td>0.674890</td>\n","      <td>0.671326</td>\n","      <td>0.674055</td>\n","      <td>0.143069</td>\n","      <td>0.010020</td>\n","      <td>0.723160</td>\n","      <td>0.068595</td>\n","      <td>19.300231</td>\n","      <td>0.005677</td>\n","      <td>...</td>\n","      <td>0.682909</td>\n","      <td>0.689504</td>\n","      <td>0.677206</td>\n","      <td>0.692105</td>\n","      <td>0.662307</td>\n","      <td>0.689504</td>\n","      <td>0.966600</td>\n","      <td>0.673108</td>\n","      <td>7.179743</td>\n","      <td>no big change</td>\n","    </tr>\n","    <tr>\n","      <th>2199</th>\n","      <td>0.674110</td>\n","      <td>0.676227</td>\n","      <td>0.672440</td>\n","      <td>0.676004</td>\n","      <td>0.312048</td>\n","      <td>0.010509</td>\n","      <td>0.755154</td>\n","      <td>0.068595</td>\n","      <td>21.857938</td>\n","      <td>0.008792</td>\n","      <td>...</td>\n","      <td>0.682505</td>\n","      <td>0.689504</td>\n","      <td>0.677414</td>\n","      <td>0.691979</td>\n","      <td>0.662849</td>\n","      <td>0.689504</td>\n","      <td>0.896525</td>\n","      <td>0.674333</td>\n","      <td>7.179743</td>\n","      <td>increase</td>\n","    </tr>\n","    <tr>\n","      <th>2200</th>\n","      <td>0.675725</td>\n","      <td>0.675837</td>\n","      <td>0.668820</td>\n","      <td>0.669321</td>\n","      <td>0.279230</td>\n","      <td>0.008306</td>\n","      <td>0.536443</td>\n","      <td>0.068595</td>\n","      <td>18.491048</td>\n","      <td>0.003247</td>\n","      <td>...</td>\n","      <td>0.682505</td>\n","      <td>0.689504</td>\n","      <td>0.677475</td>\n","      <td>0.692413</td>\n","      <td>0.662537</td>\n","      <td>0.689504</td>\n","      <td>0.925453</td>\n","      <td>0.672328</td>\n","      <td>7.535366</td>\n","      <td>decrease</td>\n","    </tr>\n","    <tr>\n","      <th>2201</th>\n","      <td>0.669293</td>\n","      <td>0.671326</td>\n","      <td>0.662973</td>\n","      <td>0.664198</td>\n","      <td>0.552933</td>\n","      <td>0.005024</td>\n","      <td>0.362143</td>\n","      <td>0.068595</td>\n","      <td>15.904361</td>\n","      <td>-0.000906</td>\n","      <td>...</td>\n","      <td>0.679735</td>\n","      <td>0.689504</td>\n","      <td>0.677201</td>\n","      <td>0.691448</td>\n","      <td>0.662953</td>\n","      <td>0.689504</td>\n","      <td>0.977753</td>\n","      <td>0.667149</td>\n","      <td>7.707911</td>\n","      <td>decrease</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2201 rows × 101 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-52443c9f-8454-4d22-a9f2-4d07272efded')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-52443c9f-8454-4d22-a9f2-4d07272efded button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-52443c9f-8454-4d22-a9f2-4d07272efded');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["gen = MyDataset(train_data[0:2201],100)\n","gen = None\n","for i, j in data_generator(train_data[:2201], 100, 16, multiprocessing.cpu_count()):\n","  print(i.shape, j.shape)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MO12iL5xDTig","executionInfo":{"status":"ok","timestamp":1683125194998,"user_tz":240,"elapsed":6627,"user":{"displayName":"Praneeth","userId":"13740106769956375743"}},"outputId":"ca5bbeee-9bc8-404e-a1a9-9ec64b72f868"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-5-d26e89e12f47>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_train_tensor = torch.tensor(labels_encoded).float().clone().detach()\n"]},{"output_type":"stream","name":"stdout","text":["torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([16, 100, 100]) torch.Size([16, 3])\n","torch.Size([5, 100, 100]) torch.Size([5, 3])\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"-7QsVXMhpFWn"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Inw1vSq6mTI7"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.init as init\n","from torch.utils.data import DataLoader, TensorDataset\n","from sklearn.metrics import accuracy_score, precision_score\n","from tqdm import tqdm\n","\n","class LSTM(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, output_dim):\n","        super(LSTM, self).__init__()\n","        self.hidden_dim = hidden_dim\n","        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=1, batch_first=True) #num_layers = 2\n","        self.dropout = nn.Dropout(p=0.2)\n","        self.fc = nn.Linear(hidden_dim, output_dim)\n","        self.softmax = nn.Softmax(dim=1)\n","        \n","        # Use Xavier initialization for weights\n","        init.xavier_uniform_(self.lstm.weight_ih_l0)\n","        init.orthogonal_(self.lstm.weight_hh_l0)\n","        init.constant_(self.lstm.bias_ih_l0, 0.0)\n","        init.constant_(self.lstm.bias_hh_l0, 0.0)\n","        init.xavier_uniform_(self.fc.weight)\n","        init.constant_(self.fc.bias, 0.0)\n","\n","    def forward(self, x):\n","        h0 = torch.zeros(1, x.size(0), self.hidden_dim).requires_grad_().to(device)\n","        c0 = torch.zeros(1, x.size(0), self.hidden_dim).requires_grad_().to(device)\n","        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n","        out = self.dropout(out)\n","        out = self.fc(out[:, -1, :])\n","        out = out.view(-1, 3)\n","        out = self.softmax(out)\n","        return out\n","\n","# Check if CUDA is available\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","source":["def train_model(batch_generator):\n","  # Evaluate each model for 10 epochs\n","  # Initialize the model\n","  learning_rate = 0.001\n","  num_epochs = 10\n","  input_dim = 100\n","  hidden_dim =  64 \n","  # output_dim = y_train_tensor.shape[1]\n","  output_dim = 3\n","  num_models = 1\n","  # Define the loss function and optimizer\n","  criterion = nn.CrossEntropyLoss()\n","  for i in range(num_models):\n","    # print('Model no', i+1)\n","\n","    # Initialize the model\n","    model = LSTM(input_dim, hidden_dim, output_dim).to(device)\n","\n","    # Define the optimizer and scheduler for the current model\n","    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n","\n","    # Checkpointing parameters for the current model\n","    checkpoint_interval = 1\n","    checkpoint_file = f'lstm_checkpoint_{i}.pth'\n","\n","    # Define early stopping parameters\n","    best_loss = float('inf')\n","    early_stop_counter = 0\n","    early_stop_patience = 3\n","\n","    # Train the current model for 10 epochs\n","    for epoch in range(num_epochs):\n","      # Set model to train mode\n","      model.train()\n","      # model.double()\n","\n","      # Iterate over batches\n","      for x_batch, y_batch in tqdm(generator):\n","          # Move data to device\n","          x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n","          # Cast x_batch to float32\n","          x_batch = x_batch.float()\n","          print(x_batch.shape)\n","\n","          # Forward pass\n","          outputs = model(x_batch)\n","          loss = criterion(outputs, y_batch)\n","\n","          # Backward and optimize\n","          optimizer.zero_grad()\n","          loss.backward()\n","          optimizer.step()\n","\n","      # Print the loss for every 10 epochs\n","      if (epoch + 1) % 10 == 0:\n","          print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch + 1, num_epochs, loss.item()))\n","\n","      # Check if current model has reached early stopping criteria\n","      print(loss.item())\n","      if loss.item() < best_loss:\n","          best_loss = loss.item()\n","          early_stop_counter = 0\n","      else:\n","          early_stop_counter += 1\n","\n","      # if early_stop_counter >= early_stop_patience:\n","      #     print(f\"Training for model {i} stopped early at epoch {epoch+1} due to early stopping\")\n","      #     break\n","\n","      # Save checkpoint at regular intervals\n","      if (epoch + 1) % checkpoint_interval == 0:\n","          torch.save({\n","              'epoch': epoch + 1,\n","              'model_state_dict': model.state_dict(),\n","              'optimizer_state_dict': optimizer.state_dict(),\n","              'loss': loss.item(),\n","          }, checkpoint_file)\n","\n","      # Step the scheduler\n","      scheduler.step()\n","\n","    # Delete variables to free up memory\n","    del model, optimizer, scheduler\n","\n","    # Empty the cache to free up GPU memory\n","    torch.cuda.empty_cache()\n"],"metadata":{"id":"qgqXau2NQJ9Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(train_data.iloc[:2201*20, :])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4Ekvde5LKzFF","executionInfo":{"status":"ok","timestamp":1683126704358,"user_tz":240,"elapsed":224,"user":{"displayName":"Praneeth","userId":"13740106769956375743"}},"outputId":"7036e214-9aa5-4d1d-8208-561420b0d741"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["44020"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ANi8Cfqx-UY2","cellView":"code"},"outputs":[],"source":["seq_length = 100 # Define sequence length\n","batch_size = 64 # Create data loader\n","\n","# Concatenate tensors of empty(Provding early shape can provide performance improvement)\n","start = 0\n","# if start == 0:\n","# X_train_tensor = torch.empty((batch_size*160, seq_length, 100), dtype=torch.float32)\n","# y_train_tensor = torch.empty((batch_size*160, 3), dtype=torch.float32)\n","generator = prepare_train_data(train_data.iloc[:2201*200, :], seq_length, batch_size)\n","# while start < batch_size*160:\n","# Prepare the data\n","# start = iter_generator(generator, start)\n","# print(start)"]},{"cell_type":"code","source":["train_model(generator)"],"metadata":{"id":"3NWUpleQQOQP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_batch.shape"],"metadata":{"id":"4YBOnzBCrZ2t","executionInfo":{"status":"ok","timestamp":1683114207428,"user_tz":240,"elapsed":243,"user":{"displayName":"Pran En","userId":"14838666787094319667"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"cca28e32-7b22-4474-a6fa-bcb4992b14b4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([21010, 3])"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MxaGiAypA0GP"},"outputs":[],"source":["#Creating n subsets of data to train n models on them. This will help to avoid memory issue and all the models will be able to capture different patterns of data.\n","def create_subset(X, y, num_models):\n","  X_subsets = torch.chunk(X, num_models, dim=0)\n","  y_subsets = torch.chunk(y, num_models, dim=0)\n","  return X_subsets, y_subsets"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":216,"status":"ok","timestamp":1683073548130,"user":{"displayName":"Pran En","userId":"14838666787094319667"},"user_tz":240},"id":"S4ovii5ndnlU","outputId":"fd899689-ce16-4feb-e5df-bda865d33419"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Tensor,\n"," torch.Size([336160, 100, 100]),\n"," torch.Tensor,\n"," torch.Size([336160, 3]))"]},"metadata":{},"execution_count":25}],"source":["type(X_train_tensor), X_train_tensor.shape, type(y_train_tensor), y_train_tensor.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":516,"status":"ok","timestamp":1682995874316,"user":{"displayName":"Pran En","userId":"14838666787094319667"},"user_tz":240},"id":"697eKUoi7Sw1","outputId":"3b79b5bd-80be-44e6-a6ea-c42c4e265c4f"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([868400, 30, 10])\n","torch.Size([217100, 30, 10])\n","torch.Size([868400, 3])\n","torch.Size([217100, 3])\n"]},{"data":{"text/plain":["(None, None, None, None)"]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["print(X_train_split.shape), print(X_val_split.shape), print(y_train_split.shape), print(y_val_split.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Cx5lPxl43m42"},"outputs":[],"source":["# del y_train\n","# del labels_encoded\n","# train_file.close()\n","# del train_file\n","# del train_data\n","# del y_train_tensor\n","# del X_train_tensor\n","# del train_loader\n","# del X_batch\n","# del y_batch"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":209,"status":"ok","timestamp":1683114127564,"user":{"displayName":"Pran En","userId":"14838666787094319667"},"user_tz":240},"id":"vVXR8LjXIeS4","outputId":"250bd380-f496-4fe3-f5df-4d0ed77a21b5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":9}],"source":["import gc\n","gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YtjyjcManXzk"},"outputs":[],"source":["# Initialize the model\n","learning_rate = 0.001\n","num_epochs = 10\n","input_dim = X_train_tensor.shape[2]\n","hidden_dim = 32 #64 \n","output_dim = y_train_tensor.shape[1]\n","num_models = 10\n","\n","# Define the loss function and optimizer\n","criterion = nn.CrossEntropyLoss()\n","\n","def train_model():      \n","  # Evaluate each model for 10 epochs\n","  for i in range(num_models):\n","      print('Model no', i+1)\n","      #Version 2\n","      # Create PyTorch DataLoader\n","      train_dataset = TensorDataset(X_train_subsets[i], y_train_subsets[i])\n","      train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=False)\n","      \n","      # Initialize the model\n","      model = LSTM(input_dim, hidden_dim, output_dim).to(device)\n","\n","      # Define the optimizer and scheduler for the current model\n","      optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","      scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n","\n","      # Checkpointing parameters for the current model\n","      checkpoint_interval = 1\n","      checkpoint_file = f'lstm_checkpoint_{i}.pth'\n","\n","      #Version 2\n","      # Define early stopping parameters\n","      best_loss  = float('inf')\n","      early_stop_counter = 0\n","      early_stop_patience  = 3\n","\n","      # Train the current model for 10 epochs\n","      for epoch in range(num_epochs):\n","          # Set model to train mode\n","          model.train()\n","\n","          # Iterate over batches\n","          for x_batch, y_batch in tqdm(train_dataloader):\n","              # Move data to device\n","              x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n","\n","              # Forward pass\n","              outputs = model(x_batch)\n","              loss = criterion(outputs, y_batch)\n","\n","              # Backward and optimize\n","              optimizer.zero_grad()\n","              loss.backward()\n","              optimizer.step()\n","\n","          \n","\n","          # Print the loss for every 10 epochs\n","          if (epoch+1) % 10 == 0:\n","              print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))\n","\n","          # Check if current model has reached early stopping criteria\n","          print(loss.item())\n","          if loss.item() < best_loss:\n","              best_loss = loss.item()\n","              early_stop_counter = 0\n","          else:\n","              early_stop_counter += 1\n","\n","          if early_stop_counter >= early_stop_patience:\n","              print(f\"Training for model {i} stopped early at epoch {epoch+1} due to early stopping\")\n","              break\n","\n","          # Save checkpoint at regular intervals\n","          if (epoch+1) % checkpoint_interval == 0:\n","              torch.save({\n","                  'epoch': epoch+1,\n","                  'model_state_dict': model.state_dict(),\n","                  'optimizer_state_dict': optimizer.state_dict(),\n","                  'loss': loss.item(),\n","              }, checkpoint_file)\n","\n","          # Step the scheduler\n","          scheduler.step()        \n","\n","        \n","      # Delete variables to free up memory\n","      del model, optimizer, scheduler, train_dataset\n","\n","      # Empty the cache to free up GPU memory\n","      torch.cuda.empty_cache()\n","  return    "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20965,"status":"ok","timestamp":1683064877687,"user":{"displayName":"Pran En","userId":"14838666787094319667"},"user_tz":240},"id":"HpVlnbTD_9Nl","outputId":"a28c9b0f-8484-45e1-b639-4e1ef140197a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model no 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [00:01<00:00, 27.79it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1.081726312637329\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [00:00<00:00, 359.94it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1.0920677185058594\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [00:00<00:00, 370.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1.0842463970184326\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [00:00<00:00, 394.93it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1.1076174974441528\n","Training for model 0 stopped early at epoch 4 due to early stopping\n","Model no 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [00:00<00:00, 344.58it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1.0997602939605713\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [00:00<00:00, 345.44it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1.1135356426239014\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [00:00<00:00, 374.30it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1.1321948766708374\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [00:00<00:00, 378.59it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1.088295817375183\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [00:00<00:00, 359.82it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1.075323462486267\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [00:00<00:00, 384.59it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1.063912272453308\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [00:00<00:00, 355.92it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1.0714330673217773\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [00:00<00:00, 358.21it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1.1103172302246094\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [00:00<00:00, 327.65it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1.0660569667816162\n","Training for model 1 stopped early at epoch 9 due to early stopping\n","Model no 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [00:00<00:00, 374.97it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1.1196484565734863\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [00:00<00:00, 363.53it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1.1078165769577026\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [00:00<00:00, 363.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1.0896424055099487\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [00:00<00:00, 387.61it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1.06300687789917\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [00:00<00:00, 380.69it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1.1017729043960571\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [00:00<00:00, 389.75it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1.07615065574646\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [00:00<00:00, 387.45it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1.073542833328247\n","Training for model 2 stopped early at epoch 7 due to early stopping\n","Model no 4\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [00:00<00:00, 367.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1.0943727493286133\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [00:00<00:00, 389.66it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1.1004804372787476\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [00:00<00:00, 296.91it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1.0611552000045776\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [00:00<00:00, 245.75it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1.0932831764221191\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [00:00<00:00, 276.47it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1.0881705284118652\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [00:00<00:00, 274.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1.1041125059127808\n","Training for model 3 stopped early at epoch 6 due to early stopping\n","Model no 5\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [00:00<00:00, 294.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1.08082914352417\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [00:00<00:00, 272.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1.0933897495269775\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [00:00<00:00, 287.86it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1.042515754699707\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [00:00<00:00, 294.83it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1.0726603269577026\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [00:00<00:00, 293.52it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1.068379282951355\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [00:00<00:00, 267.96it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1.0885183811187744\n","Training for model 4 stopped early at epoch 6 due to early stopping\n","Model no 6\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [00:00<00:00, 262.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1.0947011709213257\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [00:00<00:00, 361.84it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1.0640671253204346\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [00:00<00:00, 385.91it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1.0599979162216187\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [00:00<00:00, 382.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1.0837301015853882\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [00:00<00:00, 397.22it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1.0534991025924683\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [00:00<00:00, 372.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1.071290135383606\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [00:00<00:00, 389.75it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1.042439341545105\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [00:00<00:00, 358.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1.0312483310699463\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [00:00<00:00, 397.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1.0497949123382568\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [00:00<00:00, 390.72it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [10/10], Loss: 1.0301\n","1.030076026916504\n","Model no 7\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [00:00<00:00, 380.57it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1.0791767835617065\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [00:00<00:00, 358.17it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1.0832494497299194\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [00:00<00:00, 401.21it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1.0651568174362183\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [00:00<00:00, 384.32it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1.044883131980896\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [00:00<00:00, 287.84it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1.0364904403686523\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [00:00<00:00, 388.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1.0380300283432007\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [00:00<00:00, 345.45it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1.0635713338851929\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [00:00<00:00, 386.93it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1.0506093502044678\n","Training for model 6 stopped early at epoch 8 due to early stopping\n","Model no 8\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [00:00<00:00, 391.68it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1.1290113925933838\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [00:00<00:00, 346.28it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1.1019011735916138\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [00:00<00:00, 388.96it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1.0890754461288452\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [00:00<00:00, 385.77it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1.0846617221832275\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [00:00<00:00, 342.02it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1.0737338066101074\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [00:00<00:00, 358.73it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1.0900037288665771\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [00:00<00:00, 304.43it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1.0697615146636963\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [00:00<00:00, 306.88it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1.094727635383606\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [00:00<00:00, 378.40it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1.0934548377990723\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [00:00<00:00, 377.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [10/10], Loss: 1.0837\n","1.08368718624115\n","Training for model 7 stopped early at epoch 10 due to early stopping\n","Model no 9\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [00:00<00:00, 330.50it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1.046051263809204\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [00:00<00:00, 378.91it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1.053025722503662\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [00:00<00:00, 371.19it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1.0595672130584717\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [00:00<00:00, 381.67it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1.0494871139526367\n","Training for model 8 stopped early at epoch 4 due to early stopping\n","Model no 10\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [00:00<00:00, 312.46it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1.1345807313919067\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [00:00<00:00, 370.98it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1.0943025350570679\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [00:00<00:00, 392.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1.0788580179214478\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [00:00<00:00, 379.91it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1.1235790252685547\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [00:00<00:00, 399.18it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1.092431902885437\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [00:00<00:00, 382.71it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1.068505883216858\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [00:00<00:00, 321.59it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1.1018667221069336\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [00:00<00:00, 358.47it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1.1034066677093506\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [00:00<00:00, 377.66it/s]"]},{"output_type":"stream","name":"stdout","text":["1.091912865638733\n","Training for model 9 stopped early at epoch 9 due to early stopping\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["X_train_subsets, y_train_subsets = create_subset(X_train_tensor, y_train_tensor, num_models)\n","train_model()"]},{"cell_type":"code","source":["def validation_call(X_data=None, y_data=None, model=None, isValidation=True, data_generator=None):\n","  # Evaluate the current model on the training set\n","  cnt = 0\n","  for X_data, y_data in data_generator:    \n","    with torch.no_grad():\n","      X_data = X_data.float()\n","      outputs = model.forward(X_data.to(device))          \n","\n","    # Convert predicted and true labels to one-hot encodings\n","    predicted_labels = torch.argmax(outputs, dim=1).to(device)\n","    if isValidation:\n","      predictions.append(predicted_labels)\n","    true_labels = torch.argmax(y_data, dim=1).to(device)\n","\n","    # Calculate precision for each class\n","    precisions = []\n","    accuracies = []\n","    for i in range(3):\n","      # if i == 2: # positive class\n","      #     true_positives = torch.sum((predicted_labels == i) & (true_labels == i))\n","      #     false_positives = torch.sum((predicted_labels == i) & (true_labels != 2))\n","      #     precision = true_positives.float() / (true_positives + false_positives).float()\n","      #     accuracies.append(torch.mean((predicted_labels == true_labels).float() * (true_labels == i).float()))\n","      # else: # negative class\n","      #     true_negatives = torch.sum((predicted_labels == i) & (true_labels == i) & (true_labels != 2))\n","      #     false_positives = torch.sum((predicted_labels == i) & (true_labels != i) & (true_labels != 2))\n","      #     precision = true_negatives.float() / (true_negatives + false_positives).float()\n","      #     accuracies.append(torch.mean((predicted_labels == true_labels).float() * (true_labels != i).float()))\n","      # precisions.append(precision)\n","\n","        true_positives = torch.sum((predicted_labels == i) & (true_labels == i))\n","        false_positives = torch.sum((predicted_labels == i) & ((true_labels != i) & (true_labels != 3)))\n","        precision = true_positives.float() / (true_positives + false_positives).float()\n","        if torch.isnan(true_positives) or torch.isnan(false_positives) or torch.isnan(precision):\n","          if cnt == 0:\n","            print(i, predicted_labels, true_labels, true_positives, false_positives)\n","          cnt += 1\n","        precisions.append(precision)\n","        accuracy = torch.mean((predicted_labels == true_labels).float() * (true_labels == i).float())\n","        accuracies.append(accuracy)\n","\n","    # Calculate average precision and accuracy\n","    avg_precision = torch.mean(torch.tensor(precisions))\n","    avg_accuracy = torch.mean(torch.tensor(accuracies))\n","\n","    # Calculate percentage of positive predictions\n","    percent_positive = torch.mean((predicted_labels == 2).float())\n","    # Free Memory\n","  del model\n","  torch.cuda.empty_cache()\n","  return [avg_precision, avg_accuracy, percent_positive]"],"metadata":{"id":"3c4ytBwpdyuv"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kmfZmXDDQg_-"},"outputs":[],"source":["\n","predictions = []\n","def perform_validation(num_models, data_generator):\n","  metrics = []\n","  # Evaluate each model on the primary training set and the validation set\n","  for i in range(num_models):\n","    # print(f\"\\nModel {i+1}\")\n","    # Load the trained model from the checkpoint file\n","    checkpoint_file = f'lstm_checkpoint_{i}.pth'\n","    checkpoint = torch.load(checkpoint_file)\n","    print(\"Model\", i)\n","    model = LSTM(100, 16, 3).to(device)\n","    model.load_state_dict(checkpoint['model_state_dict'])\n","    curr = {\"train\": [], \"val\": []}\n","    # curr[\"train\"] = validation_call(X_train_subsets[i], y_train_subsets[i], model, False, data_generator)\n","    curr[\"val\"] = validation_call(None, None, model, True, data_generator)\n","    metrics.append(curr)\n","    \n","  return metrics"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xlLuGlUrHecD"},"outputs":[],"source":["def print_table(metrics):\n","    header = ['Model', 'Train', '', '', 'Validation', '', '', '', '']\n","    subheader = ['', '', 'Precision', 'Accuracy', '% Positive', 'Precision', 'Accuracy', '% Positive']\n","    print(\" {:<10} {:<10} {:<14} {:<10} {:<10} {:<14} {:<14} {:<14}\".format(*header))\n","    print(\"{:<10} {:<0} {:<10} {:<10} {:<14} {:<10} {:<10} {:<14}\".format(*subheader))\n","\n","    for i in range(len(metrics)):\n","        row =[i+1] + [f\"{val:.4f}\" for val in metrics[i]['train']] + [f\"{val:.4f}\" for val in metrics[i]['val']]\n","        print(\"{:<11} {:<10} {:<10} {:<14} {:<10} {:<10} {:<14}\".format(*row))\n","    return"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"onGJLrhNbaBn"},"outputs":[],"source":["#Load Feature Engineered Stock dataset: 100 Features including labels\n","with open('data_with_features_clean_test.pkl', 'rb') as test_file: #To do: Change file name.\n","  test_data = pickle.load(test_file)\n","\n","test_data = test_data.iloc[:200*stock_len]"]},{"cell_type":"code","source":["# Concatenate tensors of empty(Provding early shape can provide performance improvement)\n","start = 0\n","# if start == 0:\n","# X_train_tensor = torch.empty((batch_size*160, seq_length, 100), dtype=torch.float32)\n","# y_train_tensor = torch.empty((batch_size*160, 3), dtype=torch.float32)\n","generator = prepare_train_data(test_data, seq_length, batch_size)"],"metadata":{"id":"t05balygblHl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["metrics"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":165},"id":"oCX_5cV0lefK","executionInfo":{"status":"error","timestamp":1683127015846,"user_tz":240,"elapsed":196,"user":{"displayName":"Praneeth","userId":"13740106769956375743"}},"outputId":"49bb7854-0b72-4b58-f5a1-8ae4d3e9b556"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-71cacc06bb91>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'metrics' is not defined"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":515},"executionInfo":{"elapsed":81814,"status":"error","timestamp":1683127156355,"user":{"displayName":"Praneeth","userId":"13740106769956375743"},"user_tz":240},"id":"V4nZ9aNGEKex","outputId":"1ddce434-b416-47ee-bb5e-488beac47800"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model 0\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-5-d26e89e12f47>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_train_tensor = torch.tensor(labels_encoded).float().clone().detach()\n"]},{"output_type":"stream","name":"stdout","text":["0 tensor([2, 2, 2, 2, 2, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1,\n","        2, 1, 1, 1, 1, 1, 2, 1], device='cuda:0') tensor([0, 0, 1, 0, 0, 2, 2, 2, 0, 2, 0, 0, 2, 2, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0,\n","        2, 2, 2, 2, 2, 0, 0, 2], device='cuda:0') tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n"," Model      Train                                Validation                                             \n","            Precision  Accuracy   % Positive     Precision  Accuracy   % Positive    \n"]},{"output_type":"error","ename":"IndexError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-30-4c175584ebff>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# X_val_subsets, y_val_subsets = create_subset(X_test_tensor, y_test_tensor, num_models)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperform_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-27-e9dd46974ff5>\u001b[0m in \u001b[0;36mprint_table\u001b[0;34m(metrics)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34mf\"{val:.4f}\"\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34mf\"{val:.4f}\"\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{:<11} {:<10} {:<10} {:<14} {:<10} {:<10} {:<14}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: Replacement index 4 out of range for positional args tuple"]}],"source":["# X_val_subsets, y_val_subsets = create_subset(X_test_tensor, y_test_tensor, num_models)\n","metrics = perform_validation(1, generator)\n","print_table(metrics)"]},{"cell_type":"code","source":["print(metrics)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pYsbsQgGM7b2","executionInfo":{"status":"ok","timestamp":1683127264999,"user_tz":240,"elapsed":208,"user":{"displayName":"Praneeth","userId":"13740106769956375743"}},"outputId":"9781d880-5184-43b5-a37d-78f9515be5aa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[{'train': [], 'val': [tensor(0.0833), tensor(0.0417), tensor(0.3750, device='cuda:0')]}]\n"]}]},{"cell_type":"code","source":["start = 0\n","ans = []\n","X_test_tensor = torch.empty((batch_size*5, seq_length, 100), dtype=torch.float32)\n","y_test_tensor = torch.empty((batch_size*5, 3), dtype=torch.float32)\n","for X_batch, y_batch in generator:\n","  print(type(X_batch), type(y_batch), X_batch.shape, y_batch.shape, X_batch.shape[0], y_batch.shape[0])\n","  end = start + X_batch.shape[0]\n","  X_test_tensor[start:end] = X_batch\n","  y_test_tensor[start:end] = y_batch\n","  start = end"],"metadata":{"id":"DXZcRO-5igNK"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wAaMaIjZbgFm"},"outputs":[],"source":["seq_length = 100 # Define sequence length\n","batch_size = 2201 - seq_length # Create data loader\n","\n","# Prepare the data\n","generator = prepare_train_data(test_data, seq_length, batch_size)\n","\n","seq_length = 30 # Define sequence length\n","batch_size = 32 # Create data loader\n","\n","# # Prepare the data\n","X_test_tensor, y_test_tensor = prepare_train_data(test_data, seq_length, batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":103970,"status":"ok","timestamp":1683049326472,"user":{"displayName":"Pran En","userId":"14838666787094319667"},"user_tz":240},"id":"5Bw7PXNdRwfx","outputId":"a557a8dc-b996-4a45-bdc0-18c48dfe4377"},"outputs":[{"name":"stdout","output_type":"stream","text":["Open                                        0.672106\n","High                                        0.674597\n","Low                                         0.670546\n","Close                                       0.672106\n","Volume                                      0.208023\n","                                           ...      \n","linear_reg_forecast (LRF)                   0.689504\n","mass_index (Mass_Index)                     1.004993\n","median_price (Median Price)                 0.672572\n","money_flow_index (Money Flow Index)        27.384836\n","Label                                  no big change\n","Name: 1, Length: 101, dtype: object\n","High                                         4.574482\n","Close                                       23.298265\n","awesome_oscillator (AO)                    -53.453593\n","bollinger_percent_b (percent_b)            -31.491068\n","cmo (cmo)                                   -6.443804\n","disparity_index (disparity_index)           16.613215\n","elder_impulse_system (elder_bullish)        28.448544\n","elder_impulse_system (elder_bearish)        30.298143\n","gator_oscillator (gator)                    20.932837\n","macd (Signal)                                -2.34359\n","Label                                   no big change\n","Name: 0, dtype: object\n"]}],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.decomposition import IncrementalPCA\n","from sklearn.feature_selection import SelectKBest, f_regression\n","\n","# Concatenate all dataframes in train_data into a single dataframe\n","df = train_data\n","\n","# Separate the target variable (stock price) from the features\n","y = df['Label']\n","X = df.drop(['Label'], axis=1)\n","\n","# Split the dataset into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n","\n","# Instantiate IncrementalPCA and fit to the training data in chunks\n","batch_size = 1000\n","n_components = 20\n","ipca = IncrementalPCA(n_components=n_components, batch_size=batch_size)\n","for i in range(0, len(X_train), batch_size):\n","    X_train_batch = X_train.iloc[i:i+batch_size]\n","    ipca.partial_fit(X_train_batch)\n","\n","# Transform the training and testing data in chunks\n","X_train_pca = []\n","for i in range(0, len(X_train), batch_size):\n","    X_train_batch = X_train.iloc[i:i+batch_size]\n","    X_train_pca_batch = ipca.transform(X_train_batch)\n","    X_train_pca.append(X_train_pca_batch)\n","X_train_pca = np.vstack(X_train_pca)\n","\n","X_test_pca = []\n","for i in range(0, len(X_test), batch_size):\n","    X_test_batch = X_test.iloc[i:i+batch_size]\n","    X_test_pca_batch = ipca.transform(X_test_batch)\n","    X_test_pca.append(X_test_pca_batch)\n","X_test_pca = np.vstack(X_test_pca)\n","\n","# # Instantiate PCA and fit to the training data\n","# pca = PCA(n_components=20)\n","# pca.fit(X_train)\n","\n","# # Transform the training and testing data\n","# X_train_pca = pca.transform(X_train)\n","# X_test_pca = pca.transform(X_test)\n","\n","# Instantiate SelectKBest and fit to the training data\n","selector = SelectKBest(f_regression, k=10)\n","selector.fit(X_train_pca, y_train.cat.codes.astype('int').to_numpy())\n","\n","# Transform the training and testing data\n","X_train_selected = selector.transform(X_train_pca)\n","X_test_selected = selector.transform(X_test_pca)\n","\n","selected_indices = selector.get_support(indices=True)\n","\n","# Select only the columns with the selected indices\n","X_train_pca_df = pd.DataFrame(data=X_train_selected, columns=X_train.columns[selected_indices])\n","X_test_pca_df = pd.DataFrame(data=X_test_selected, columns=X_train.columns[selected_indices])\n","\n","# Assign labels to X_train_pca_df\n","X_train_pca_df['Label'] = y_train.values\n","X_test_pca_df['Label'] = y_test.values\n","\n","train_data = pd.concat([X_train_pca_df, X_test_pca_df])\n","\n","# Print the first row of the original training data and the PCA-transformed data\n","print(df.iloc[0])\n","print(X_train_pca_df.iloc[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GCGSaOEBkDv9"},"outputs":[],"source":["del X_train_pca_df, X_train_selected, X_train_pca, X_train_batch\n","del X_test_pca_df, X_test_selected, X_test_pca, X_test_batch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xqNII3yJ3ukE"},"outputs":[],"source":["seq_length = 30 # Define sequence length\n","batch_size = 16 # Create data loader\n","\n","# Prepare the data\n","X_train_tensor, y_train_tensor = prepare_train_data(train_data, seq_length, batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QEwMJRfhj22H"},"outputs":[],"source":["from collections import Counter\n","final_predictions = [Counter(p).most_common(1)[0][0] for p in zip(*predictions)]\n","# final_predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":237,"status":"ok","timestamp":1682997162846,"user":{"displayName":"Pran En","userId":"14838666787094319667"},"user_tz":240},"id":"Zioo7r1paRMV","outputId":"85850aa9-27b2-4aaa-faee-d8a6374885da"},"outputs":[{"data":{"text/plain":["torch.Size([21710])"]},"execution_count":96,"metadata":{},"output_type":"execute_result"}],"source":["final_predictions.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":224,"status":"ok","timestamp":1682997281800,"user":{"displayName":"Pran En","userId":"14838666787094319667"},"user_tz":240},"id":"ZngzqlwduBUx","outputId":"5db1e7f2-b468-4f76-f1b5-a1fc19a1d47b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Precision tensor(0.7090)\n","Precision tensor(0.2365)\n","Precision tensor(0.2800, device='cuda:0')\n"]}],"source":[" # Calculate precision for each class\n","precisions = []\n","accuracies = []\n","# final_predictions = torch.argmax(final_predictions, dim=1).to(device)\n","true_labels = torch.argmax(y_val_subsets[0], dim=1).to(device)\n","for i in range(3):\n","  true_positives = torch.sum((final_predictions == i) & (true_labels == i))\n","  false_positives = torch.sum((final_predictions == i) & ((true_labels != i) & (true_labels != 3)))\n","  precision = true_positives.float() / (true_positives + false_positives).float()\n","  precisions.append(precision)\n","  accuracy = torch.mean((final_predictions == true_labels).type(torch.FloatTensor) * (true_labels == i).type(torch.FloatTensor))\n","  accuracies.append(accuracy)\n","# Calculate average precision and accuracy\n","avg_precision = torch.mean(torch.tensor(precisions))\n","avg_accuracy = torch.mean(torch.tensor(accuracies))\n","\n","# Calculate percentage of positive predictions\n","percent_positive = torch.mean((final_predictions == 2).float())\n","\n","print(\"Precision\", avg_precision)\n","print(\"Precision\", avg_accuracy)\n","print(\"Precision\", percent_positive)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O3OiKFhZT5uq"},"outputs":[],"source":["#Step 5\n","import numpy as np\n","from sklearn.ensemble import VotingClassifier\n","from sklearn.ensemble import AdaBoostClassifier\n","\n","# Load the saved LSTM models and their predictions on the primary training and validation sets\n","models = []\n","preds_train = []\n","preds_val = []\n","for i in range(10):\n","    model = torch.load(f'lstm_checkpoint_{i}.pth')\n","    # preds_train.append(np.load('lstm_preds_train_' + str(i) + '.npy'))\n","    # preds_val.append(np.load('lstm_preds_val_' + str(i) + '.npy'))\n","    models.append(('lstm_' + str(i), model))\n","\n","# Voting ensemble\n","voting_ensemble = VotingClassifier(models, voting='hard')\n","voting_ensemble.fit(np.concatenate(preds_train, axis=1), y_train)\n","train_preds_voting = voting_ensemble.predict(np.concatenate(preds_train, axis=1))\n","val_preds_voting = voting_ensemble.predict(np.concatenate(preds_val, axis=1))\n","\n","# # Blending ensemble\n","# blend_train = np.concatenate([p.reshape(-1, 1) for p in preds_train], axis=1)\n","# blend_val = np.concatenate([p.reshape(-1, 1) for p in preds_val], axis=1)\n","# blend_model = LogisticRegression()\n","# blend_model.fit(blend_train, y_train)\n","# train_preds_blend = blend_model.predict(blend_train)\n","# val_preds_blend = blend_model.predict(blend_val)\n","\n","# # Adaboost ensemble\n","# adaboost = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=10)\n","# adaboost.fit(np.concatenate(preds_train, axis=1), y_train)\n","# train_preds_adaboost = adaboost.predict(np.concatenate(preds_train, axis=1))\n","# val_preds_adaboost = adaboost.predict(np.concatenate(preds_val, axis=1))\n","\n","# # Compute evaluation metrics\n","# train_acc_voting = accuracy_score(y_train, train_preds_voting)\n","# train_acc_blend = accuracy_score(y_train, train_preds_blend)\n","# train_acc_adaboost = accuracy_score(y_train, train_preds_adaboost)\n","# val_acc_voting = accuracy_score(y_val, val_preds_voting)\n","# val_acc_blend = accuracy_score(y_val, val_preds_blend)\n","# val_acc_adaboost = accuracy_score(y_val, val_preds_adaboost)\n","# train_f1_voting = f1_score(y_train, train_preds_voting, average='macro')\n","# train_f1_blend = f1_score(y_train, train_preds_blend, average='macro')\n","# train_f1_adaboost = f1_score(y_train, train_preds_adaboost, average='macro')\n","# val_f1_voting = f1_score(y_val, val_preds_voting, average='macro')\n","# val_f1_blend = f1_score(y_val, val_preds_blend, average='macro')\n","# val_f1_adaboost = f1_score(y_val, val_preds_adaboost, average='macro')\n","\n","# # Print the evaluation metrics\n","# print('Method\\tDataset\\tAccuracy\\tF1-score')\n","# print('Voting\\tTrain\\t{}\\t{}'.format(train_acc_voting, train_f1_voting))\n","# print('Voting\\tVal\\t{}\\t{}'.format(val_acc_voting, val_f1_voting))\n","# print('Blending\\tTrain\\t{}\\t{}'.format(train_acc_blend, train_f1_blend))\n","# print('Blending\\tVal\\t{}\\t{}'.format(val_acc_blend, val_f1_blend))\n","# print('Adaboost\\tTrain\\t{}\\t{}'.format(train_acc_adaboost, train_f1_adaboost))\n","# print('Adaboost\\tVal\\t{}\\t{}'.format\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vF6MLNcxet-R"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","\n","class Seq2Seq(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, output_dim):\n","        super(Seq2Seq, self).__init__()\n","        self.encoder = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n","        self.decoder = nn.LSTM(hidden_dim, output_dim, batch_first=True)\n","        \n","    def forward(self, x):\n","        # Encoder\n","        _, (hidden, cell) = self.encoder(x)\n","        \n","        # Decoder\n","        batch_size, sequence_length, _ = x.size()\n","        output = torch.zeros(batch_size, sequence_length, self.decoder.hidden_size).to(x.device)\n","        h = hidden\n","        c = cell\n","        for t in range(sequence_length):\n","            out, (h, c) = self.decoder(output[:, t:t+1, :], (h, c))\n","            output[:, t, :] = out.squeeze()\n","        \n","        return output\n"]},{"cell_type":"code","source":["import torch\n","from torch.utils.data import DataLoader, Dataset, TensorDataset\n","import multiprocessing\n","\n","class MyDatasetSuper(Dataset):\n","    def __init__(self, X, y):\n","        self.X = X\n","        self.y = y        \n","    \n","    def __getitem__(self, idx):\n","        return self.X[idx], self.y[idx]\n","    \n","    def __len__(self):\n","        return len(self.X)\n","\n","class MyDataset(Dataset):\n","    def __init__(self, df, seq_length):\n","        self.X = []\n","        self.y = []\n","        \n","        labels = df.iloc[:, -1].values # Extract labels from the last column\n","        cnt = len(labels)\n","        print(cnt)\n","        df = df.iloc[:, :-1] # Remove labels column from the DataFrame        \n","        values = torch.tensor(df.values) # Convert DataFrame to tensor\n","\n","        # Create input/output sequences\n","        while cnt != 0:\n","          for i in range(seq_length, stock_len):\n","            self.X.append(values[i-seq_length:i, :])\n","            self.y.append(labels[i])\n","          cnt -= 2201\n","    \n","    def __getitem__(self, idx):\n","        return self.X[idx], self.y[idx]\n","    \n","    def __len__(self):\n","        return len(self.X)\n","\n","def data_generator(train_data, seq_length, batch_size, num_workers):\n","    train_dataset = MyDataset(train_data, seq_length)\n","\n","    # Create DataLoader\n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n","\n","    for X_batch, y_batch in train_loader:\n","        # Convert labels to tensor\n","        y_train = np.array(y_batch)\n","        labels_encoded = torch.zeros((len(y_train), 3), dtype=torch.float32)\n","        labels_encoded[y_train == 'increase', 2] = 1\n","        labels_encoded[y_train == 'no big change', 1] = 1\n","        labels_encoded[y_train == 'decrease', 0] = 1\n","        y_train_tensor = torch.tensor(labels_encoded).float().clone().detach()\n","\n","        yield X_batch, y_train_tensor\n","\n","    # Free up memory\n","    del train_dataset\n","    del labels_encoded\n","    del X_batch, y_batch\n","\n","def load_data_in_chunks(filename, chunk_size):\n","    with open(filename, 'rb') as f:\n","        while True:\n","            try:\n","                chunk = []\n","                for i in range(chunk_size):\n","                    chunk.append(pickle.load(f))\n","                yield chunk\n","            except EOFError:\n","                break\n","\n","# def prepare_train_data(train_data = None, seq_length = 100, batch_size = 32):\n","num_workers=multiprocessing.cpu_count() #parallel computing\n","\n","# Optimization 4 (Using data generator)\n","generator = data_generator(train_data, seq_length, batch_size, num_workers)\n","\n","# Iterate over data chunks and create the dataset\n","# X = []\n","# y = []\n","# for chunk in data_chunks:\n","#     for i in chunk:\n","#       train_dataset = MyDataset(i, seq_length)\n","#       X.extend(train_dataset.X)\n","#       y.extend(train_dataset.y)\n","#       del train_dataset        \n","  \n","# train_dataset = MyDataset(train_data, seq_length)\n","# train_dataset = MyDatasetSuper(X, y)\n","\n","#Optimzation 1: Dataset and Dataloaders for batch processing\n","#Optimization 2: (num_of_workers, pin_memory(GPU specific))\n","# Create DataLoader\n","\n","# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n","\n","# Concatenate tensors of empty(Provding early shape can provide performance improvement)\n","# X_train_tensor = torch.empty((len(train_dataset), seq_length, train_dataset[0][0].shape[1]), dtype=torch.float32)\n","\n","# #Optimization 3: Avoid torch.cat on large datasets.\n","# start = 0\n","# for X_batch, y_batch in train_loader:\n","#     end = start + X_batch.shape[0]\n","#     X_train_tensor[start:end] = X_batch\n","#     start = end\n","\n","# # Convert labels to tensor\n","# y_train = np.array(train_dataset.y)\n","# labels_encoded = torch.zeros((len(y_train), 3), dtype=torch.float32)\n","# labels_encoded[y_train == 'increase', 2] = 1\n","# labels_encoded[y_train == 'no big change', 1] = 1\n","# labels_encoded[y_train == 'decrease', 0] = 1\n","# # y_train_tensor = torch.tensor(labels_encoded).float() #Warning Issued\n","# y_train_tensor = torch.tensor(labels_encoded).float().clone().detach()\n","\n","# # Free up memory\n","# del train_dataset\n","# del labels_encoded\n","# del start, end, seq_length, num_workers, X_batch, y_batch\n","\n","  # return X_train_tensor, y_train_tensor"],"metadata":{"id":"HbmnuJZEUmkf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define the split point\n","split_point = int(len(X_train_tensor) * 0.8) # 80% train, 20% validation\n","\n","# Split the data into training and validation sets\n","X_train_tensor = X_train_tensor.float()\n","X_train_split = X_train_tensor[:split_point]\n","y_train_split = y_train_tensor[:split_point]\n","X_val_split = X_train_tensor[split_point:]\n","y_val_split = y_train_tensor[split_point:]"],"metadata":{"id":"6DMm0oep034Y"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1OVIwecTeWT8mV-MLDIB6PTY9XxYv7P9m","timestamp":1683118403422},{"file_id":"11qohwNbxcNBvJBoKMvpJrtZy2LNWpc95","timestamp":1682809990606},{"file_id":"1W2sswuGKRxM4PCb83Zm2BbNnaoZPv4tk","timestamp":1682310416896}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}