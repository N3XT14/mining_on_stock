{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"eJufmR74ZMxp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683036804973,"user_tz":240,"elapsed":43,"user":{"displayName":"Yash Oswal","userId":"08926553451935908326"}},"outputId":"4f60b3e0-0bf4-41a9-e650-67cd1e8d2571"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["#Necessary Imports\n","!pip install ta\n","import numpy as np\n","import pandas as pd\n","import os\n","import pickle\n","import ta\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","#Data Source Location\n","os.chdir(\"/content/drive/My Drive/mining-on-stock\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NJouJ6rpZt4H"},"outputs":[],"source":["#500 Stock dataset\n","with open('testing_set1.pkl', 'rb') as train_file:\n","  train_data = pickle.load(train_file)"]},{"cell_type":"code","source":["len(train_data[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jmTFRU0nz8Ij","executionInfo":{"status":"ok","timestamp":1683036888025,"user_tz":240,"elapsed":15,"user":{"displayName":"Yash Oswal","userId":"08926553451935908326"}},"outputId":"8f2842e9-0929-40be-bd17-442913acf2c0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["889"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m8HK54gxZ0eP"},"outputs":[],"source":["# Separate the features and the labels\n","temp_data = train_data.drop(['vwap (None)'], axis=1)\n","temp_data = temp_data.dropna(subset=['Label'])\n","\n","X = temp_data.iloc[:, :-1]\n","y = temp_data.iloc[:, -1]\n","\n","# Check for NaN values\n","# print(X.isnull().sum())\n","X = X.fillna(X.mean())\n","# print(X.isnull().sum())\n","\n","labels = y\n","labels_encoded = np.zeros((len(labels), 3))\n","labels_encoded[labels == 'increase', 2] = 1\n","labels_encoded[labels == 'no big change', 1] = 1\n","labels_encoded[labels == 'decrease', 0] = 1\n","y_encoded = labels_encoded"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CuEnZi9baUaZ"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","#Fix Max value i.e normalize\n","X[np.isfinite(X) == False] = np.finfo('float64').max\n","X = np.clip(X, a_min=None, a_max=1e10)\n","\n","# Split data into training set and validation set\n","# X_train, X_val, y_train, y_val = train_test_split(X, y_encoded, test_size=0.2, random_state=42) #test_size 0.5/0.2 (to be decided)\n","# print(len(X_train), len(X_val), len(y_train), len(y_val))\n","\n","# X_train = X_train.dropna()\n","# print(len(X_train), len(X_val), len(y_train), len(y_val))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1682548375010,"user":{"displayName":"Yash Oswal","userId":"08926553451935908326"},"user_tz":240},"id":"p2Zr6pgoxkBr","outputId":"3b378c68-4faa-4ee3-ba3c-b8a79006af4d"},"outputs":[{"output_type":"stream","name":"stdout","text":["(1100500, 109) (1100500, 108) (1100500, 3)\n"]}],"source":["print(temp_data.shape, X.shape, y_encoded.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"84rndnGJN7c4"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","from tensorflow import keras\n","from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n","from sklearn.metrics import accuracy_score, precision_score, confusion_matrix\n","\n","# Split data into training and validation sets\n","X = X.values\n","y = y_encoded\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Reshape X_train and X_val to represent past 100 trading records for each stock (TO BE VERIFIED) (USED RESHAPE TECHNIQUE) (TRY SLIDING WINDOW TECHNIQUE)\n","X_train = X_train.reshape(-1, 100, X_train.shape[1])\n","X_val = X_val.reshape(-1, 100, X_val.shape[1])\n","\n","# Convert labels to 3-element vectors\n","# convert labels to integers\n","# le = LabelEncoder()\n","# y_train = le.fit_transform(y_train)\n","# y_val = le.transform(y_val)\n","# y_train = keras.utils.to_categorical(y_train, num_classes=3)\n","# y_val = keras.utils.to_categorical(y_val, num_classes=3)\n","\n","# Train Random Forest model\n","# rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n","# rf_model.fit(X_train.reshape(-1, X_train.shape[2]), y_train.reshape(-1,))\n","\n","# # Evaluate model on training and validation sets\n","# for name, X, y in [('Training', X_train, y_train), ('Validation', X_val, y_val)]:\n","#     y_pred = rf_model.predict(X.reshape(-1, X.shape[2])).reshape(-1, 3)\n","#     acc = accuracy_score(np.argmax(y, axis=1), np.argmax(y_pred, axis=1))\n","#     precision = precision_score(np.argmax(y, axis=1), np.argmax(y_pred, axis=1), pos_label=2)\n","#     pos_pred = np.sum(np.argmax(y_pred, axis=1) == 2) / y_pred.shape[0]\n","#     print(f'{name} accuracy: {acc:.4f}, precision: {precision:.4f}, percentage of positive predictions: {pos_pred:.4f}')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HKqp6L6ZdJ8N"},"outputs":[],"source":["X_train.reshape(-1, X_train.shape[2]).shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5w4T34GlPKgj"},"outputs":[],"source":["rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n","rf_model.fit(X_train.reshape(-1, X_train.shape[2]), y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1CcusmF90hn4"},"outputs":[],"source":["from sklearn.model_selection import RandomizedSearchCV\n","from sklearn.ensemble import RandomForestClassifier\n","from scipy.stats import randint\n","\n","# Define the parameter grid for the randomized search\n","param_dist = {'n_estimators': randint(100, 1000),\n","              'max_features': ['sqrt', 'log2'],\n","              'max_depth': [None] + list(randint(3, 20).rvs(5)),\n","              'min_samples_split': randint(2, 10)}\n","\n","# Create a Random Forest classifier object\n","rf_model = RandomForestClassifier(random_state=42)\n","\n","# Perform randomized search cross-validation\n","random_search = RandomizedSearchCV(estimator=rf_model,\n","                                   param_distributions=param_dist,\n","                                   cv=5,\n","                                   n_iter=2,\n","                                   n_jobs=-1,\n","                                   random_state=42)\n","\n","# Fit the randomized search to the training data\n","random_search.fit(X_train.reshape(-1, X_train.shape[2]), y_train)\n","\n","# Get the best estimator\n","best_estimator = random_search.best_estimator_\n","\n","# Evaluate the performance of the best estimator on the validation data\n","accuracy = best_estimator.score(X_val.reshape(-1, X_val.shape[2]), y_val)\n","precision = precision_score(y_val, best_estimator.predict(X_val.reshape(-1, X_val.shape[2])))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pw_yb6Zv8otN"},"outputs":[],"source":["from sklearn.model_selection import cross_val_score\n","from sklearn.ensemble import RandomForestClassifier\n","from itertools import product\n","\n","# Define the parameter grid\n","param_grid = {'n_estimators': [100, 500, 1000],\n","              'max_features': ['sqrt', 'log2'],\n","              'max_depth': [None, 5, 10, 15],\n","              'min_samples_split': [2, 5, 8]}\n","\n","# Generate all combinations of hyperparameters\n","hyperparams = list(product(*param_grid.values()))\n","\n","# Create a list to store the models\n","models = []\n","\n","# Train a model for each combination of hyperparameters\n","for params in hyperparams:\n","    rf_model = RandomForestClassifier(random_state=42, **dict(zip(param_grid.keys(), params)))\n","    scores = cross_val_score(rf_model, X_train.reshape(-1, X_train.shape[2]), y_train, cv=5)\n","    mean_score = scores.mean()\n","    models.append({'params': params, 'score': mean_score})\n","    break\n","\n","# Find the model with the highest mean score\n","best_model = max(models, key=lambda x: x['score'])\n","\n","# Train the best model on the full training set\n","best_rf_model = RandomForestClassifier(random_state=42, **dict(zip(param_grid.keys(), best_model['params'])))\n","best_rf_model.fit(X_train.reshape(-1, X_train.shape[2]), y_train)\n","\n","# Evaluate the performance of the best model on the validation set\n","accuracy = best_rf_model.score(X_val.reshape(-1, X_val.shape[2]), y_val)\n","precision = precision_score(y_val, best_rf_model.predict(X_val.reshape(-1, X_val.shape[2])))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GM16gZ_C9ddW","colab":{"base_uri":"https://localhost:8080/","height":380},"executionInfo":{"status":"error","timestamp":1682549907939,"user_tz":240,"elapsed":23087,"user":{"displayName":"Yash Oswal","userId":"08926553451935908326"}},"outputId":"9a81172f-a33a-40af-b6e2-f7e6fbb35d28"},"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-0352721d23d6>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Fit the model with cross-validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m cv_results = cross_validate(rf_model, \n\u001b[0m\u001b[1;32m      9\u001b[0m                              \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                              \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;31m# independent, and that it is pickle-able.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0mparallel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     results = parallel(\n\u001b[0m\u001b[1;32m    267\u001b[0m         delayed(_fit_and_score)(\n\u001b[1;32m    268\u001b[0m             \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1083\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1085\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1086\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    902\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    471\u001b[0m             \u001b[0;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0;31m# since correctness does not rely on using threads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             trees = Parallel(\n\u001b[0m\u001b[1;32m    474\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1086\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1088\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1089\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    902\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"balanced\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    887\u001b[0m         \"\"\"\n\u001b[1;32m    888\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m    890\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    377\u001b[0m             )\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# Define the Random Forest classifier with hyperparameters\n","from sklearn.model_selection import cross_validate\n","from sklearn.ensemble import RandomForestClassifier\n","\n","rf_model = RandomForestClassifier(n_estimators=500, max_depth=10, min_samples_split=5, max_features='sqrt', random_state=42)\n","\n","# Fit the model with cross-validation\n","cv_results = cross_validate(rf_model, \n","                             X_train.reshape(-1, X_train.shape[2]), \n","                             y_train, \n","                             cv=2, \n","                             scoring=('accuracy', 'precision'),\n","                             return_train_score=True)\n","\n","# Print the mean accuracy and precision scores across the 5 folds\n","print(\"Accuracy (train): {:.3f}\".format(cv_results['train_accuracy'].mean()))\n","print(\"Accuracy (test): {:.3f}\".format(cv_results['test_accuracy'].mean()))\n","print(\"Precision (train): {:.3f}\".format(cv_results['train_precision'].mean()))\n","print(\"Precision (test): {:.3f}\".format(cv_results['test_precision'].mean()))\n","\n","# Fit the model on the entire training set\n","rf_model.fit(X_train.reshape(-1, X_train.shape[2]), y_train)\n","\n","# Evaluate the model on the validation set\n","accuracy = rf_model.score(X_val.reshape(-1, X_val.shape[2]), y_val)\n","precision = precision_score(y_val, rf_model.predict(X_val.reshape(-1, X_val.shape[2])))\n","print(\"Accuracy (validation): {:.3f}\".format(accuracy))\n","print(\"Precision (validation): {:.3f}\".format(precision))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hzB0zMPfAVo7"},"outputs":[],"source":["joblib.dump(random_search, 'random_search_rf.pkl')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":84695,"status":"ok","timestamp":1682512201427,"user":{"displayName":"Yash Oswal","userId":"08926553451935908326"},"user_tz":240},"id":"Ly5SdslSh8BX","outputId":"5e2e7c4a-4e51-42d1-ca75-dfa77eff9e28"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training accuracy: 1.0000, precision: 1.0000, percentage of positive predictions: 0.3328\n","Validation accuracy: 0.7482, precision: 0.7624, percentage of positive predictions: 0.2270\n"]}],"source":["for name, X, y in [('Training', X_train, y_train), ('Validation', X_val, y_val)]:\n","    y_pred = rf_model.predict(X.reshape(-1, X.shape[2])).reshape(-1, 3)\n","    acc = accuracy_score(np.argmax(y, axis=1), np.argmax(y_pred, axis=1))\n","    precision = precision_score(np.argmax(y, axis=1), np.argmax(y_pred, axis=1), average=\"weighted\")\n","    pos_pred = np.sum(np.argmax(y_pred, axis=1) == 2) / y_pred.shape[0]\n","    print(f'{name} accuracy: {acc:.4f}, precision: {precision:.4f}, percentage of positive predictions: {pos_pred:.4f}')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":69577,"status":"ok","timestamp":1682518476061,"user":{"displayName":"Yash Oswal","userId":"08926553451935908326"},"user_tz":240},"id":"82JiHbHek6G-","outputId":"20d59538-128e-4286-b3aa-ec4fe5c49bf5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training accuracy: 1.0000, precision: 1.0000, percentage of positive predictions: 0.3338\n","Validation accuracy: 0.7482, precision: 0.7624, percentage of positive predictions: 0.3211\n"]}],"source":["for name, X, y in [('Training', X_train, y_train), ('Validation', X_val, y_val)]:\n","    y_pred = rf_model.predict(X.reshape(-1, X.shape[2])).reshape(-1, 3)\n","    acc = accuracy_score(np.argmax(y, axis=1), np.argmax(y_pred, axis=1))\n","    precision = precision_score(np.argmax(y, axis=1), np.argmax(y_pred, axis=1), average=\"weighted\")\n","    pos_pred = np.sum(np.argmax(y_pred, axis=1) == 2) / y_pred.shape[0]\n","    print(f'{name} accuracy: {acc:.4f}, precision: {precision:.4f}, percentage of positive predictions: {pos_pred:.4f}')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6enLMJlPslRI","outputId":"92dffe48-6644-4dc4-a436-16966dd521eb"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/20], Loss: nan, Accuracy: 0.3336, Precision: 0.1112\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [2/20], Loss: nan, Accuracy: 0.3336, Precision: 0.1112\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [3/20], Loss: nan, Accuracy: 0.3336, Precision: 0.1112\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [4/20], Loss: nan, Accuracy: 0.3336, Precision: 0.1112\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [5/20], Loss: nan, Accuracy: 0.3336, Precision: 0.1112\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [6/20], Loss: nan, Accuracy: 0.3336, Precision: 0.1112\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [7/20], Loss: nan, Accuracy: 0.3336, Precision: 0.1112\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [8/20], Loss: nan, Accuracy: 0.3336, Precision: 0.1112\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [9/20], Loss: nan, Accuracy: 0.3336, Precision: 0.1112\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [10/20], Loss: nan, Accuracy: 0.3336, Precision: 0.1112\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [11/20], Loss: nan, Accuracy: 0.3336, Precision: 0.1112\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [12/20], Loss: nan, Accuracy: 0.3336, Precision: 0.1112\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [13/20], Loss: nan, Accuracy: 0.3336, Precision: 0.1112\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [14/20], Loss: nan, Accuracy: 0.3336, Precision: 0.1112\n"]}],"source":["import torch\n","import torch.nn as nn\n","from sklearn.model_selection import train_test_split\n","\n","# Load and split data into primary training set and validation set\n","# train_data = pd.read_csv(\"train_data.csv\")\n","# X = train_data.iloc[:, :-1]\n","# y = train_data.iloc[:, -1]\n","# labels = y\n","# labels_encoded = np.zeros((len(labels), 3))\n","# labels_encoded[labels == 'increase', 2] = 1\n","# labels_encoded[labels == 'no big change', 1] = 1\n","# labels_encoded[labels == 'decrease', 0] = 1\n","# y_encoded = labels_encoded\n","\n","X_train, X_val, y_train, y_val = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n","\n","# Define the neural network architecture\n","class Net(nn.Module):\n","    def __init__(self, input_size, hidden_size1, hidden_size2, hidden_size3, output_size):\n","        super(Net, self).__init__()\n","        self.fc1 = nn.Linear(input_size, hidden_size1)\n","        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n","        self.fc3 = nn.Linear(hidden_size2, hidden_size3)\n","        self.fc4 = nn.Linear(hidden_size3, output_size)\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x):\n","        out = self.fc1(x)\n","        out = self.relu(out)\n","        out = self.fc2(out)\n","        out = self.relu(out)\n","        out = self.fc3(out)\n","        out = self.relu(out)\n","        out = self.fc4(out)\n","        return out\n","\n","# Initialize the neural network\n","input_size = X_train.shape[1]\n","hidden_size1 = 256\n","hidden_size2 = 128\n","hidden_size3 = 64\n","output_size = 3\n","\n","net = Net(input_size, hidden_size1, hidden_size2, hidden_size3, output_size)\n","\n","# Define the loss function and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n","\n","# Train the neural network\n","num_epochs = 20\n","batch_size = 128\n","\n","for epoch in range(num_epochs):\n","    for i in range(0, len(X_train), batch_size):\n","        batch_X = torch.Tensor(X_train[i:i+batch_size].values)\n","        batch_y = torch.Tensor(y_train[i:i+batch_size])\n","        \n","        # Forward pass\n","        outputs = net(batch_X)\n","        loss = criterion(outputs, torch.max(batch_y, 1)[1])\n","        \n","        # Backward and optimize\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        \n","    # Compute accuracy and precision on validation set\n","    with torch.no_grad():\n","        val_X = torch.Tensor(X_val.values)\n","        val_y = torch.Tensor(y_val)\n","        val_outputs = net(val_X)\n","        _, predicted = torch.max(val_outputs.data, 1)\n","        total = val_y.size(0)\n","        correct = (predicted == torch.max(val_y, 1)[1]).sum().item()\n","        accuracy = correct / total\n","        precision = precision_score(torch.max(val_y, 1)[1], predicted, average='macro')\n","        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Accuracy: {accuracy:.4f}, Precision: {precision:.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1682465938931,"user":{"displayName":"Yash Oswal","userId":"08926553451935908326"},"user_tz":240},"id":"X0stNdGLaHZG","outputId":"c5d6f879-7126-4d9d-b0a3-3b40a9cfc796"},"outputs":[{"name":"stdout","output_type":"stream","text":["1100500 1100500\n"]}],"source":["from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n","\n","one_hot_encoded = pd.get_dummies(temp_data[\"Label\"])\n","y_ = np.array(one_hot_encoded)\n","y_encoded = list(y_)\n","print(len(X), len(y_encoded))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VdYtRf4wasXo"},"outputs":[],"source":["from sklearn.metrics import accuracy_score, precision_score, make_scorer\n","def result_metrics(y_train, y_train_pred, y_val, y_val_pred, cv_results):\n","\n","  train_accuracy = accuracy_score(y_train, y_train_pred)\n","  train_precision = precision_score(y_train, y_train_pred, average='weighted')\n","\n","  val_accuracy = accuracy_score(y_val, y_val_pred)\n","  val_precision = precision_score(y_val, y_val_pred, average='weighted')\n","\n","  # calculate the percentage of positive predictions (to be decided)\n","  train_pct_pos = sum(y_train_pred == np.array([0,0,1])) / len(y_train_pred) * 100\n","  val_pct_pos = sum(y_val_pred == np.array([0,0,1])) / len(y_val_pred) * 100\n","\n","  # print the results\n","  print(\"Training set accuracy:\", train_accuracy)\n","  print(\"Training set precision:\", train_precision)\n","  print(\"Validation set accuracy:\", val_accuracy)\n","  print(\"Validation set precision:\", val_precision)\n","  print(\"Percentage of positive predictions on training set:\", train_pct_pos)\n","  print(\"Percentage of positive predictions on validation set:\", val_pct_pos)\n","  print(\"Mean accuracy score from cross-validation:\", cv_results['test_accuracy'].mean())\n","  print(\"Standard deviation of accuracy score from cross-validation:\", cv_results['test_accuracy'].std())\n","  print(\"Mean precision score from cross-validation:\", cv_results['test_precision'].mean())\n","  print(\"Standard deviation of precision score from cross-validation:\", cv_results['test_precision'].std())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jZt8rn77cVmA"},"outputs":[],"source":["import joblib\n","def save_model(model, model_name):\n","  # save the trained model object into pkl file\n","  joblib.dump(model, f'{model_name}.pkl')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ahbzUByxxMOQ"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","\n","class ConvNet(nn.Module):\n","    def __init__(self):\n","        super(ConvNet, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n","        self.relu1 = nn.ReLU()\n","        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n","        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n","        self.relu2 = nn.ReLU()\n","        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n","        self.fc1 = nn.Linear(8 * 8 * 32, 128)\n","        self.relu3 = nn.ReLU()\n","        self.fc2 = nn.Linear(128, 10)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.relu1(x)\n","        x = self.pool1(x)\n","        x = self.conv2(x)\n","        x = self.relu2(x)\n","        x = self.pool2(x)\n","        x = x.view(-1, 8 * 8 * 32)\n","        x = self.fc1(x)\n","        x = self.relu3(x)\n","        x = self.fc2(x)\n","        return x\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"dmZVcW_8anuW","outputId":"57a74114-87f4-4284-d9a2-06fdd60699d4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training set accuracy: 0.8244547932757837\n","Training set precision: 0.8805115950590375\n","Validation set accuracy: 0.7709541117673785\n","Validation set precision: 0.8247498540599081\n","Percentage of positive predictions on training set: [65.40731486 73.24068605 35.11063153]\n","Percentage of positive predictions on validation set: [65.05270332 73.44934121 35.31985461]\n","Mean accuracy score from cross-validation: 0.7692776010904134\n","Standard deviation of accuracy score from cross-validation: 0.0006599712915076703\n","Mean precision score from cross-validation: 0.8236228956345977\n","Standard deviation of precision score from cross-validation: 0.0006606699787418656\n"]}],"source":["#HistGradientBoostingClassifier\n","\n","from sklearn.multioutput import MultiOutputClassifier\n","from sklearn.ensemble import HistGradientBoostingClassifier\n","from sklearn.model_selection import cross_validate\n","\n","# define the model with optimized hyperparameters\n","hist_model = HistGradientBoostingClassifier(\n","    max_depth=10,\n","    max_iter=200,\n","    learning_rate=0.1,\n","    min_samples_leaf=50,\n","    max_leaf_nodes=5000,\n","    validation_fraction=0.1,\n","    n_iter_no_change=10,\n","    verbose=1,\n","    random_state=42,\n","    # loss='log_loss'\n",")\n","\n","# define the scoring metrics\n","scoring = {'accuracy': make_scorer(accuracy_score), 'precision': make_scorer(precision_score, average='weighted')}\n","hist_model = MultiOutputClassifier(hist_model, n_jobs=-1)\n","\n","# compute the cross-validation scores\n","cv_results = cross_validate(hist_model, X_train, y_train, cv=5, scoring=scoring)\n","\n","# train the model on the training sethist_model = MultiOutputClassifier(hist_model, n_jobs=-1)\n","hist_model.fit(X_train, y_train)d\n","\n","# predict on the training set and compute the accuracy and precision scores\n","y_train_pred = hist_model.predict(X_train)\n","\n","# predict on the validation set and compute the accuracy and precision scores\n","y_val_pred = hist_model.predict(X_val)\n","\n","#Call to result_metrics\n","result_metrics(y_train, y_train_pred, y_val, y_val_pred, cv_results)\n","\n","#save the model\n","save_model(hist_model, 'hist_model_cv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bzTfdJK0Zx7Y"},"outputs":[],"source":["from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import cross_validate\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.pipeline import Pipeline\n","\n","# Define preprocessing pipeline\n","preprocessor = Pipeline([\n","    ('scaler', StandardScaler())\n","])\n","\n","# Define logistic regression model with L2 regularization and cross-validation\n","lr = LogisticRegression(penalty='l2', solver='lbfgs', max_iter=3000, random_state=42, class_weight='balanced')\n","\n","# Define the final pipeline that combines preprocessing and logistic regression\n","lr_model = Pipeline([\n","    ('preprocessor', preprocessor),\n","    ('lr', lr)\n","])\n","\n","# Define the scoring metrics\n","scoring = {'accuracy': make_scorer(accuracy_score), 'precision': make_scorer(precision_score, average='weighted')}\n","\n","# Compute cross-validation scores\n","# cv_results = cross_validate(lr_model, X, y_encoded, cv=2, scoring=scoring)\n","\n","# Fit the model to the training data\n","lr_model.fit(X_train, y_train)\n","\n","# Predict on the training set and compute the accuracy and precision scores\n","y_train_pred = lr_model.predict(X_train)\n","\n","# Predict on the validation set and compute the accuracy and precision scores\n","y_val_pred = lr_model.predict(X_val)\n","\n","#Call to result_metrics\n","result_metrics(y_train, y_train_pred, y_val, y_val_pred, cv_results)\n","\n","#save the model\n","save_model(lr_model, 'lr_model_cv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MhcPJwTt3GVX"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader, Dataset\n","\n","# Define a custom dataset class\n","class MyDataset(Dataset):\n","    def __init__(self, data):\n","        self.data = data\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, index):\n","        x = self.data[index, :-1]\n","        y = self.data[index, -1]\n","        return x, y\n","\n","# Define the RNN model\n","class MyRNN(nn.Module):\n","    def __init__(self, input_size, hidden_size, output_size):\n","        super(MyRNN, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n","        self.fc = nn.Linear(hidden_size, output_size)\n","\n","    def forward(self, x):\n","        out, hidden = self.rnn(x)\n","        out = out.contiguous().view(-1, self.hidden_size)\n","        out = self.fc(out)\n","        return out\n","\n","\n","# Instantiate the dataset and dataloader\n","dataset = MyDataset(data)\n","dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n","\n","# Instantiate the RNN model\n","model = MyRNN(input_size=train_data.shape[1] - 1, hidden_size=16, output_size=1)\n","\n","# # Define the loss function and optimizer\n","criterion = nn.BCEWithLogitsLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","\n","# # Train the model\n","num_epochs = 10\n","for epoch in range(num_epochs):\n","    for i, (inputs, labels) in enumerate(dataloader):\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels.unsqueeze(1))\n","        loss.backward()\n","        optimizer.step()\n","\n","        if (i+1) % 10 == 0:\n","            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(dataloader)}], Loss: {loss.item():.4f}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x5h5qGck3Bu1"},"outputs":[],"source":["import numpy as np\n","\n","num_samples = 1101000\n","seq_length = 11\n","num_features = 110\n","\n","# assuming `data` is your input data of shape (1101000, 110)\n","data = np.random.rand(1101000, 110)\n","\n","# truncate data to a multiple of (seq_length * num_features)\n","data = data[:num_samples * seq_length * num_features]\n","\n","# reshape data into (num_samples, seq_length, num_features)\n","train_data_reshaped = data.reshape(1101000, 11, 10)\n","\n","# convert data to a PyTorch tensor\n","data = torch.from_numpy(data).float()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":397},"executionInfo":{"elapsed":1315,"status":"error","timestamp":1682479375607,"user":{"displayName":"Yash Oswal","userId":"08926553451935908326"},"user_tz":240},"id":"D5MZfJuYj2M6","outputId":"add9e5eb-fff3-4d70-8e19-3a57492c88f3"},"outputs":[{"ename":"TypeError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-80-cec5d17c4d8f>\u001b[0m in \u001b[0;36m<cell line: 79>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_models\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m108\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m     \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0mtrain_losses_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-80-cec5d17c4d8f>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, X_train, y_train, X_val, y_val, num_epochs, batch_size, learning_rate)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStockDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0mval_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStockDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-12-45bd18ec64c3>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, features, labels)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool."]}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import TensorDataset, DataLoader\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","\n","\n","class LSTM(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, num_layers, output_dim):\n","        super().__init__()\n","        self.hidden_dim = hidden_dim\n","        self.num_layers = num_layers\n","\n","        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n","        self.fc = nn.Linear(hidden_dim, output_dim)\n","\n","    def forward(self, x, hx=None, cx=None):\n","        if hx is None and cx is None:\n","            if len(x.shape) == 2:\n","                x = x.unsqueeze(2)  # add an extra dimension for the number of features\n","            batch_size, seq_len, num_features = x.shape\n","            hx = torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(x.device)\n","            cx = torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(x.device)\n","        else:\n","            batch_size = hx.shape[1]\n","\n","        out, (hn, cn) = self.lstm(x, (hx, cx))\n","        out = out[:, -1, :].view(batch_size, -1)  # use only the last output of the sequence and reshape\n","\n","        out = self.fc(out)\n","\n","        return out\n","\n","\n","# Define the training function\n","def train_model(model, X_train, y_train, X_val, y_val, num_epochs=10, batch_size=128, learning_rate=0.001):\n","    train_losses = []\n","    val_losses = []\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","    train_dataset = StockDataset(X_train, y_train)\n","    val_dataset = StockDataset(X_val, y_val)\n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n","    for epoch in range(num_epochs):\n","        model.train()\n","        running_loss = 0.0\n","        for inputs, labels in train_loader:\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","            optimizer.zero_grad()\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels.argmax(dim=1))\n","            loss.backward()\n","            optimizer.step()\n","            running_loss += loss.item()\n","        train_loss = running_loss / len(train_loader)\n","        train_losses.append(train_loss)\n","        model.eval()\n","        running_loss = 0.0\n","        for inputs, labels in val_loader:\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","            with torch.no_grad():\n","                outputs = model(inputs)\n","                loss = criterion(outputs, labels.argmax(dim=1))\n","                running_loss += loss.item()\n","        val_loss = running_loss / len(val_loader)\n","        val_losses.append(val_loss)\n","        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n","    return train_losses, val_losses\n","\n","# Train multiple models and save them\n","num_models = 10\n","models = []\n","train_losses_list = []\n","val_losses_list = []\n","for i in range(num_models):\n","    model = LSTM(input_dim=108, hidden_dim=64, num_layers=2, output_dim=3).to(device)\n","    train_losses, val_losses = train_model(model, X_train, y_train, X_val, y_val)\n","    models.append(model)\n","    train_losses_list.append(train_losses)\n","    val_losses_list.append(val_losses)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":397},"executionInfo":{"elapsed":3804,"status":"error","timestamp":1682480516580,"user":{"displayName":"Yash Oswal","userId":"08926553451935908326"},"user_tz":240},"id":"9tmUZEXAlyxh","outputId":"8e9c3192-b53e-4e64-f869-226011232756"},"outputs":[{"name":"stdout","output_type":"stream","text":["(1100500, 109) (1100500, 108) (1100500, 3)\n"]},{"ename":"ValueError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-46672626df53>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Convert y_train and y_val to one-hot encoded vectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/np_utils.py\u001b[0m in \u001b[0;36mto_categorical\u001b[0;34m(y, num_classes, dtype)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0;36m0.\u001b[0m \u001b[0;36m0.\u001b[0m \u001b[0;36m0.\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \"\"\"\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"int\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m     \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    891\u001b[0m               dtype='datetime64[ns]')\n\u001b[1;32m    892\u001b[0m         \"\"\"\n\u001b[0;32m--> 893\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m     \u001b[0;31m# ----------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/arrays/_mixins.py\u001b[0m in \u001b[0;36mmethod\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mflags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ndarray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/arrays/categorical.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1607\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtake_nd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_codes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1608\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_dtype_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1609\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1610\u001b[0m         \u001b[0;31m# When we're a Categorical[ExtensionArray], like Interval,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1611\u001b[0m         \u001b[0;31m# we need to ensure __array__ gets all the way to an\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'decrease'"]}],"source":["import numpy as np\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout\n","from tensorflow.keras.utils import to_categorical\n","\n","# Load the training data\n","print(temp_data.shape, X.shape, y_encoded.shape)\n","train_data = temp_data\n","\n","# Split the training data into a primary training set and a validation set\n","X_train, X_val, y_train, y_val = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n","X_train = X_train.to_numpy()\n","X_val = X_val.to_numpy()\n","\n","# Convert y_train and y_val to one-hot encoded vectors\n","y_train = to_categorical(y_train)\n","y_val = to_categorical(y_val)\n","\n","# Check the shape of X_train and y_train\n","print(X_train.shape, y_train.shape)\n","\n","# Define the neural network architecture\n","model = Sequential([\n","    Dense(128, activation='relu', input_shape=(100, train_data.shape[1]-1)),\n","    Dropout(0.2),\n","    Dense(64, activation='relu'),\n","    Dropout(0.2),\n","    Dense(3, activation='softmax')\n","])\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Train the model on the primary training set\n","model.fit(X_train.reshape(-1, 100, train_data.shape[1]-1), y_train, batch_size=128, epochs=10, validation_data=(X_val.reshape(-1, 100, train_data.shape[1]-1), y_val))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":198,"status":"ok","timestamp":1682480426289,"user":{"displayName":"Yash Oswal","userId":"08926553451935908326"},"user_tz":240},"id":"rQ0JiMrRoST4","outputId":"b8f80427-d5f9-4b33-fc05-ac46c51d967e"},"outputs":[{"data":{"text/plain":["880400"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["len(X_train)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}